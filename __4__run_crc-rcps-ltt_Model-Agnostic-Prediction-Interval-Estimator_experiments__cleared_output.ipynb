{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Check Workspace and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:12.300199Z",
     "iopub.status.busy": "2024-08-15T01:45:12.299863Z",
     "iopub.status.idle": "2024-08-15T01:45:12.305383Z",
     "shell.execute_reply": "2024-08-15T01:45:12.304577Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:12.309220Z",
     "iopub.status.busy": "2024-08-15T01:45:12.308923Z",
     "iopub.status.idle": "2024-08-15T01:45:20.148709Z",
     "shell.execute_reply": "2024-08-15T01:45:20.147728Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "\n",
    "Create function to set seeds for reproducibility\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:20.200730Z",
     "iopub.status.busy": "2024-08-15T01:45:20.200334Z",
     "iopub.status.idle": "2024-08-15T01:45:20.207109Z",
     "shell.execute_reply": "2024-08-15T01:45:20.206080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def set_seeds(offset=0):\n",
    "    import os\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(42+offset)\n",
    "\n",
    "    # Set the seed for the Python random module\n",
    "    random.seed(42+offset)\n",
    "\n",
    "    # Set the seed for TensorFlow\n",
    "    tf.random.set_seed(42+offset)\n",
    "\n",
    "    # Ensure reproducibility with certain environment variables\n",
    "    os.environ['PYTHONHASHSEED'] = str(42+offset)\n",
    "\n",
    "\n",
    "    ### Hold off on more extensive seeds (below) until verified necessary\n",
    "\n",
    "\n",
    "    # # Configure TensorFlow to use a single thread if required\n",
    "    # tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    # tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "    # # Optionally, set environment variables to control NumPy threading behavior\n",
    "    # os.environ['OMP_NUM_THREADS'] = '1'\n",
    "    # os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "    # # Example to demonstrate reproducibility\n",
    "    # print(\"Numpy Random:\", np.random.rand(3))\n",
    "    # print(\"Python Random:\", random.random())\n",
    "\n",
    "    # # TensorFlow example\n",
    "    # tf_example = tf.random.uniform([3])\n",
    "    # print(\"TensorFlow Random:\", tf_example)\n",
    "\n",
    "    # # PyTorch Example (if using PyTorch)\n",
    "    # import torch\n",
    "\n",
    "    # torch.manual_seed(42+offset)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed(42+offset)\n",
    "    #     torch.cuda.manual_seed_all(42+offset)  # if using multi-GPU.\n",
    "    #     torch.backends.cudnn.deterministic = True  # cuDNN\n",
    "    #     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # # Generate reproducible random numbers with PyTorch\n",
    "    # print(\"PyTorch Random:\", torch.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "\n",
    "Create function to start/stop logging RAM usage to file\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:20.211925Z",
     "iopub.status.busy": "2024-08-15T01:45:20.211139Z",
     "iopub.status.idle": "2024-08-15T01:45:20.219477Z",
     "shell.execute_reply": "2024-08-15T01:45:20.218515Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import threading\n",
    "import time\n",
    "from google.cloud import storage\n",
    "\n",
    "def log_memory_usage(stop_event, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        while not stop_event.is_set():\n",
    "            # Log memory usage to a local file\n",
    "            memory_info = psutil.virtual_memory()\n",
    "            gb_used = memory_info.used / (1024 ** 3)\n",
    "            mem_usage = f\"{time.ctime()}: {gb_used:.2f} GB\\n\"\n",
    "            print(mem_usage)\n",
    "            f.write(mem_usage)\n",
    "            f.flush()\n",
    "            \n",
    "            # Upload the local file to GCS\n",
    "            try:\n",
    "                destination_blob_name = f'logs/{file_name}'\n",
    "                upload_to_gcs(file_name, destination_blob_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to upload to GCS: {e}\")\n",
    "                \n",
    "            time.sleep(30)\n",
    "            \n",
    "def upload_to_gcs(source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # Get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    # Initialize a storage client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(my_bucket[5:])\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Upload the file\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "#     print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:20.223948Z",
     "iopub.status.busy": "2024-08-15T01:45:20.223076Z",
     "iopub.status.idle": "2024-08-15T01:45:20.230162Z",
     "shell.execute_reply": "2024-08-15T01:45:20.229240Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_event = threading.Event()\n",
    "memory_thread = None\n",
    "thread_lock = threading.Lock()  # To ensure thread-safe operations\n",
    "\n",
    "def RAM_start():\n",
    "    global stop_event\n",
    "    global memory_thread\n",
    "\n",
    "    with thread_lock:\n",
    "        # Clear the stop event if it is set\n",
    "        if stop_event.is_set():\n",
    "            stop_event.clear()\n",
    "\n",
    "        file_name = 'memory_usage.txt'\n",
    "        \n",
    "        # Stop the existing thread if it is running\n",
    "        if memory_thread and memory_thread.is_alive():\n",
    "            RAM_stop()\n",
    "        \n",
    "        # Create and start a new memory logging thread\n",
    "        memory_thread = threading.Thread(target=log_memory_usage, args=(stop_event, file_name))\n",
    "        memory_thread.start()\n",
    "        print(\"Memory logging started\")\n",
    "\n",
    "def RAM_stop():\n",
    "    global stop_event\n",
    "    global memory_thread\n",
    "\n",
    "    with thread_lock:\n",
    "        # Set the stop event to signal the thread to stop\n",
    "        stop_event.set()\n",
    "\n",
    "        # Wait for the thread to finish if it exists\n",
    "        if memory_thread:\n",
    "            memory_thread.join()\n",
    "            memory_thread = None  # Reset the thread to None\n",
    "            print(\"Memory logging stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:20.234577Z",
     "iopub.status.busy": "2024-08-15T01:45:20.233851Z",
     "iopub.status.idle": "2024-08-15T01:45:20.237769Z",
     "shell.execute_reply": "2024-08-15T01:45:20.236829Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RAM_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiment Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4,
     8,
     17,
     98,
     150,
     166,
     176,
     203,
     210,
     268,
     345,
     419,
     428,
     441,
     473,
     480,
     491,
     503,
     524,
     544,
     547,
     550,
     587,
     624,
     651,
     690,
     697,
     705,
     739,
     743,
     752,
     756,
     762,
     767,
     770,
     773,
     780,
     809,
     812,
     1072
    ],
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:20.243721Z",
     "iopub.status.busy": "2024-08-15T01:45:20.243439Z",
     "iopub.status.idle": "2024-08-15T01:45:21.690370Z",
     "shell.execute_reply": "2024-08-15T01:45:21.689445Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## 1. Hocevar T, Zupan B, Stålring J. Conformal Prediction with Orange. Journal of Statistical Software. 2021;98(7). doi:https://doi.org/10.18637/jss.v098.i07\n",
    "##  => https://github.com/biolab/orange3-conformal\n",
    "\n",
    "# nonconformity [1]\n",
    "def inverse_probability(probs, target_idx):\n",
    "    return 1 - probs[target_idx]\n",
    "  \n",
    "# nonconformity [1]\n",
    "def probability_margin(probs, target_idx):\n",
    "    # prediciton probabilities for one example at a time\n",
    "    assert probs.ndim == 1\n",
    "    \n",
    "    py = probs[target_idx]\n",
    "    pz = max(prob for label_idx, prob in enumerate(probs) if label_idx != target_idx)\n",
    "    return (1.0 - (py - pz)) / 2\n",
    "\n",
    "# classification [1]\n",
    "class PredictionClass:\n",
    "    \"\"\"Conformal classification prediction object,\n",
    "    which is produced by the :py:func:`ConformalClassifier.predict` method.\n",
    "\n",
    "    Attributes:\n",
    "        p (List): List of pairs (p-value, class)\n",
    "        eps (float): Default significance level (error rate).\n",
    "\n",
    "    Examples:\n",
    "        >>> train, test = next(LOOSampler(Table('iris')))\n",
    "        >>> tcp = TransductiveClassifier(InverseProbability(NaiveBayesLearner()), train)\n",
    "\n",
    "        >>> prediction = tcp.predict(test[0], 0.1)\n",
    "        >>> print(prediction.confidence(), prediction.credibility())\n",
    "\n",
    "        >>> prediction = tcp.predict(test[0])\n",
    "        >>> print(prediction.classes(0.1), prediction.classes(0.9))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, p, eps):\n",
    "        \"\"\"Initialize the prediction.\n",
    "\n",
    "        Args:\n",
    "            p (List): List of pairs (p-value, class)\n",
    "            eps (float): Default significance level (error rate).\n",
    "        \"\"\"\n",
    "        self.p = p\n",
    "        self.eps = eps\n",
    "\n",
    "    def classes(self, eps=None):\n",
    "        \"\"\" Compute the set of classes under the default or given `eps` value.\n",
    "\n",
    "        Args:\n",
    "            eps (float): Significance level (error rate).\n",
    "\n",
    "        Returns:\n",
    "            List of predicted classes.\n",
    "        \"\"\"\n",
    "        if eps is None:\n",
    "            eps = self.eps\n",
    "            assert(eps is not None)\n",
    "        return [y for p_y, y in self.p if p_y > eps]\n",
    "\n",
    "    def verdict(self, ref, eps=None):\n",
    "        \"\"\"Conformal classification prediction is correct when the actual class appears\n",
    "        among the predicted classes.\n",
    "\n",
    "        Args:\n",
    "            ref: Reference/actual class\n",
    "            eps (float): Significance level (error rate).\n",
    "\n",
    "        Returns:\n",
    "            True if the prediction with default or specified `eps` is correct.\n",
    "        \"\"\"\n",
    "        return ref in self.classes(eps)\n",
    "\n",
    "    def confidence(self):\n",
    "        \"\"\"Confidence is an efficiency measure of a single prediction.\n",
    "\n",
    "        Computes minimum :math:`\\\\mathit{eps}` that would still result in a prediction of a single label.\n",
    "        :math:`\\\\mathit{eps} = \\\\text{second\\_largest}(p_i)`\n",
    "\n",
    "        Returns:\n",
    "            float: Confidence :math:`1-\\\\mathit{eps}`.\n",
    "        \"\"\"\n",
    "        return 1-sorted([p_y for p_y, y in self.p], reverse=True)[1]\n",
    "\n",
    "    def credibility(self):\n",
    "        \"\"\"Credibility is an efficiency measure of a single prediction.\n",
    "        Small credibility indicates an unusual example.\n",
    "\n",
    "        Computes minimum :math:`\\\\mathit{eps}` that would result in an empty prediction set.\n",
    "        :math:`\\\\mathit{eps} = \\\\text{max}(p_i)`\n",
    "\n",
    "        Returns:\n",
    "            float: Credibility :math:`\\\\mathit{eps}`.\n",
    "        \"\"\"\n",
    "        return max(p_y for p_y, y in self.p)\n",
    "\n",
    "####\n",
    "\n",
    "def set_seeds(offset=0):\n",
    "    import os\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(42+offset)\n",
    "\n",
    "    # Set the seed for the Python random module\n",
    "    random.seed(42+offset)\n",
    "\n",
    "    # Set the seed for TensorFlow\n",
    "    tf.random.set_seed(42+offset)\n",
    "\n",
    "    # Ensure reproducibility with certain environment variables\n",
    "    os.environ['PYTHONHASHSEED'] = str(42+offset)\n",
    "    \n",
    "    ### Hold off on more extensive seeds (below) until verified necessary\n",
    "\n",
    "\n",
    "    # # Configure TensorFlow to use a single thread if required\n",
    "    # tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    # tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "    # # Optionally, set environment variables to control NumPy threading behavior\n",
    "    # os.environ['OMP_NUM_THREADS'] = '1'\n",
    "    # os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "    # # Example to demonstrate reproducibility\n",
    "    # print(\"Numpy Random:\", np.random.rand(3))\n",
    "    # print(\"Python Random:\", random.random())\n",
    "\n",
    "    # # TensorFlow example\n",
    "    # tf_example = tf.random.uniform([3])\n",
    "    # print(\"TensorFlow Random:\", tf_example)\n",
    "\n",
    "    # # PyTorch Example (if using PyTorch)\n",
    "    # import torch\n",
    "\n",
    "    # torch.manual_seed(42+offset)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed(42+offset)\n",
    "    #     torch.cuda.manual_seed_all(42+offset)  # if using multi-GPU.\n",
    "    #     torch.backends.cudnn.deterministic = True  # cuDNN\n",
    "    #     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # # Generate reproducible random numbers with PyTorch\n",
    "    # print(\"PyTorch Random:\", torch.rand(3))\n",
    "    print()\n",
    "    \n",
    "# Function to get a random chunk of 10 contiguous days with no NaNs in specified columns\n",
    "def get_random_chunk(df, chunk_size=10, max_attempts=10):\n",
    "    columns_to_check = ['std_hr', 'morning_hr', 'afternoon_hr', 'evening_hr', 'night_hr']\n",
    "    df = df.sort_values(by='date').reset_index(drop=True)\n",
    "    if len(df) < chunk_size:\n",
    "        return None  # Not enough data to get the desired chunk size\n",
    "    \n",
    "    attempts = 0\n",
    "    while attempts < max_attempts:\n",
    "        start_idx = np.random.randint(0, len(df) - chunk_size + 1)\n",
    "        chunk = df.iloc[start_idx:start_idx + chunk_size]\n",
    "        if not chunk[columns_to_check].isna().any().any():\n",
    "            return chunk\n",
    "        attempts += 1\n",
    "    \n",
    "    return None  # No valid chunk found after max_attempts\n",
    "\n",
    "def get_random_contiguous_chunks_with_no_missing_data(df, chunk_size=10, max_attempts=10):\n",
    "    # Apply the function to each person\n",
    "    grouped = df.groupby('person_id')\n",
    "    chunks = grouped.apply(lambda x: get_random_chunk(x, chunk_size, max_attempts)).dropna()\n",
    "\n",
    "    # Drop the multi-level index created by groupby and apply\n",
    "    chunks.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def one_hot_encode_categorical_columns(df, columns_to_encode):\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "    # Initialize OneHotEncoder\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop=None)\n",
    "\n",
    "    # Fit and transform the selected columns\n",
    "    encoded_data = encoder.fit_transform(df[columns_to_encode])\n",
    "\n",
    "    ohe_cols = encoder.get_feature_names_out(columns_to_encode)\n",
    "    \n",
    "    # Create a DataFrame with the encoded columns\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=ohe_cols)\n",
    "\n",
    "    # Reset the index to avoid misalignment when concatenating\n",
    "    encoded_df.index = df.index\n",
    "    \n",
    "    # Drop the original columns from the DataFrame\n",
    "    df = df.drop(columns=columns_to_encode)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the encoded DataFrame\n",
    "    df = pd.concat([df, encoded_df], axis=1)\n",
    "    \n",
    "    ohe_col_list = ohe_cols.tolist()\n",
    "    \n",
    "    return df, ohe_col_list\n",
    "\n",
    "def merge_demographics_and_ohe_categorical_columns(df, demographic_df):\n",
    "    df = df.merge(demographic_df, on='person_id')\n",
    "    cols = [col for col in demographic_df.columns \n",
    "            if col not in ['person_id','age']]     # ['gender', 'race', 'ethnicity', 'sex_at_birth']\n",
    "    \n",
    "    return one_hot_encode_categorical_columns(df, cols)\n",
    "\n",
    "def standard_scale_except_excluded(train, cal, test, exclude_list):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    # Columns to scale\n",
    "    columns_to_scale = [col for col in train.columns if col not in exclude_list]\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Scale the selected columns\n",
    "    train.loc[:, columns_to_scale] = scaler.fit_transform(train.loc[:, columns_to_scale])\n",
    "\n",
    "    cal.loc[:, columns_to_scale] = scaler.transform(cal.loc[:, columns_to_scale])\n",
    "    test.loc[:, columns_to_scale] = scaler.transform(test.loc[:, columns_to_scale])\n",
    "\n",
    "    return train, cal, test\n",
    "\n",
    "def get_scaled_reshaped_train_calibrate_test(df_X, df_y, num_days, random_offset, exclude_scale_cols):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Get unique person_ids\n",
    "    person_ids = df_X['person_id'].unique()\n",
    "\n",
    "    # Split into train, calibration, and test\n",
    "    person_ids_train, person_ids_temp = train_test_split(person_ids, test_size=0.6, random_state=42+random_offset)\n",
    "    person_ids_calibration, person_ids_test = train_test_split(person_ids_temp, test_size=0.5, random_state=42+random_offset)\n",
    "\n",
    "    # Filter the original dataframe to create the splits\n",
    "    df_X_train = df_X[df_X['person_id'].isin(person_ids_train)]\n",
    "    df_X_calibration = df_X[df_X['person_id'].isin(person_ids_calibration)]\n",
    "    df_X_test = df_X[df_X['person_id'].isin(person_ids_test)]\n",
    "\n",
    "    # Similarly, filter the labels\n",
    "    df_y_train = df_y.loc[person_ids_train]\n",
    "    df_y_calibration = df_y.loc[person_ids_calibration]\n",
    "    df_y_test = df_y.loc[person_ids_test]\n",
    "    \n",
    "    # Standard scale (only fitting train)\n",
    "    df_X_train, df_X_calibration, df_X_test = standard_scale_except_excluded(df_X_train, \n",
    "                                                                             df_X_calibration, \n",
    "                                                                             df_X_test, \n",
    "                                                                             exclude_list=[\n",
    "                                                                                 'person_id',\n",
    "                                                                                 'date',\n",
    "                                                                                 *exclude_scale_cols])\n",
    "    \n",
    "    # Drop the person_id from the features (assuming it's the first column)\n",
    "    X_train = df_X_train.drop(columns=['person_id','date']).values.reshape(len(person_ids_train), num_days, -1)\n",
    "    X_calibration = df_X_calibration.drop(columns=['person_id','date']).values.reshape(len(person_ids_calibration), num_days, -1)\n",
    "    X_test = df_X_test.drop(columns=['person_id','date']).values.reshape(len(person_ids_test), num_days, -1)\n",
    "\n",
    "    # Ensure that labels are aligned with the X splits\n",
    "    y_train = df_y_train.loc[person_ids_train].values\n",
    "    y_calibration = df_y_calibration.loc[person_ids_calibration].values\n",
    "    y_test = df_y_test.loc[person_ids_test].values\n",
    "\n",
    "    return (X_train, y_train, person_ids_train), (X_calibration, y_calibration, person_ids_calibration), (X_test, y_test, person_ids_test)\n",
    " \n",
    "def does_this_experiments_input_data_exist(run_num, num_days, with_demographics):\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import shutil\n",
    "             \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(os.getenv('WORKSPACE_BUCKET')[5:])\n",
    "    \n",
    "    base_path = f'data/experiments/{run_num}'\n",
    "    suffix = f'_{str(num_days)}_days_{\"with\" if with_demographics else \"wout\"}_demo.npy'\n",
    "\n",
    "    # Helper function to check if a file exists in GCS\n",
    "    def gcs_file_exists(bucket, file_path):\n",
    "        return storage.Blob(bucket=bucket, name=file_path).exists(client)\n",
    "\n",
    "    # Check if all necessary files exist in GCS\n",
    "    files_exist = all([\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_test{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_test{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_test{suffix}')\n",
    "    ])\n",
    "\n",
    "    if files_exist:\n",
    "        local_base_path = f'data/experiments/{run_num}'\n",
    "\n",
    "        # Check if all necessary files exist locally\n",
    "        local_files_exist = all([\n",
    "            os.path.exists(f'{local_base_path}/X_train{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/X_cal{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/X_test{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/y_train{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/y_cal{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/y_test{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/ids_train{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/ids_cal{suffix}'),\n",
    "            os.path.exists(f'{local_base_path}/ids_test{suffix}')\n",
    "        ])\n",
    "\n",
    "        if not local_files_exist:\n",
    "            # Download missing files from GCS to local directory\n",
    "            def download_from_gcs(bucket, remote_file, local_file):\n",
    "                blob = bucket.blob(remote_file)\n",
    "                blob.download_to_filename(local_file)\n",
    "                print(f'Downloaded {remote_file} from GCS to {local_file}.')\n",
    "\n",
    "            download_from_gcs(bucket, f'{base_path}/X_train{suffix}', f'{local_base_path}/X_train{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/X_cal{suffix}', f'{local_base_path}/X_cal{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/X_test{suffix}', f'{local_base_path}/X_test{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/y_train{suffix}', f'{local_base_path}/y_train{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/y_cal{suffix}', f'{local_base_path}/y_cal{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/y_test{suffix}', f'{local_base_path}/y_test{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/ids_train{suffix}', f'{local_base_path}/ids_train{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/ids_cal{suffix}', f'{local_base_path}/ids_cal{suffix}')\n",
    "            download_from_gcs(bucket, f'{base_path}/ids_test{suffix}', f'{local_base_path}/ids_test{suffix}')\n",
    "\n",
    "        # Load the numpy arrays from the local files\n",
    "        X_train = np.load(f'{local_base_path}/X_train{suffix}')\n",
    "        X_cal = np.load(f'{local_base_path}/X_cal{suffix}')\n",
    "        X_test = np.load(f'{local_base_path}/X_test{suffix}')\n",
    "        y_train = np.load(f'{local_base_path}/y_train{suffix}')\n",
    "        y_cal = np.load(f'{local_base_path}/y_cal{suffix}')\n",
    "        y_test = np.load(f'{local_base_path}/y_test{suffix}')\n",
    "        ids_train = np.load(f'{local_base_path}/ids_train{suffix}')\n",
    "        ids_cal = np.load(f'{local_base_path}/ids_cal{suffix}')\n",
    "        ids_test = np.load(f'{local_base_path}/ids_test{suffix}')\n",
    "\n",
    "        return True, X_train, X_cal, X_test, y_train, y_cal, y_test, ids_train, ids_cal, ids_test\n",
    "    else:\n",
    "        return False, None, None, None, None, None, None, None, None, None\n",
    "           \n",
    "def write_this_experiments_input_data_if_not_exists(run_num, num_days, with_demographics, \n",
    "                                                    X_train, y_train, ids_train, \n",
    "                                                    X_cal, y_cal, ids_cal, \n",
    "                                                    X_test, y_test, ids_test):\n",
    "    from google.cloud import storage\n",
    "    import numpy as np\n",
    "    import os\n",
    "             \n",
    "    base_path = f'data/experiments/{run_num}'\n",
    "    suffix = f'_{str(num_days)}_days_{\"with\" if with_demographics else \"wout\"}_demo.npy'\n",
    "    \n",
    "    def save_array_if_not_exists(array, filename):\n",
    "        directory = os.path.dirname(filename)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        np.save(filename, array)\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(os.getenv('WORKSPACE_BUCKET')[5:]) \n",
    "\n",
    "    # Helper function to check if a file exists in GCS\n",
    "    def gcs_file_exists(bucket, file_path):\n",
    "        return storage.Blob(bucket=bucket, name=file_path).exists(client)\n",
    "    \n",
    "    # Check if all necessary files exist in GCS\n",
    "    files_exist = all([\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/X_test{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/y_test{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_train{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_cal{suffix}'),\n",
    "        gcs_file_exists(bucket, f'{base_path}/ids_test{suffix}')\n",
    "    ])\n",
    "\n",
    "    if not files_exist:\n",
    "        # Save the files locally first\n",
    "        save_array_if_not_exists(X_train, f'{base_path}/X_train{suffix}')\n",
    "        save_array_if_not_exists(y_train, f'{base_path}/y_train{suffix}')\n",
    "        save_array_if_not_exists(ids_train, f'{base_path}/ids_train{suffix}')\n",
    "        save_array_if_not_exists(X_cal, f'{base_path}/X_cal{suffix}')\n",
    "        save_array_if_not_exists(y_cal, f'{base_path}/y_cal{suffix}')\n",
    "        save_array_if_not_exists(ids_cal, f'{base_path}/ids_cal{suffix}')\n",
    "        save_array_if_not_exists(X_test, f'{base_path}/X_test{suffix}')\n",
    "        save_array_if_not_exists(y_test, f'{base_path}/y_test{suffix}')\n",
    "        save_array_if_not_exists(ids_test, f'{base_path}/ids_test{suffix}')\n",
    "\n",
    "        # Upload files to GCS\n",
    "        def upload_to_gcs(bucket, local_file, remote_file):\n",
    "            blob = bucket.blob(remote_file)\n",
    "            blob.upload_from_filename(local_file)\n",
    "            print(f'Uploaded {local_file} to {remote_file} in GCS.')\n",
    "\n",
    "        upload_to_gcs(bucket, f'{base_path}/X_train{suffix}', f'{base_path}/X_train{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/y_train{suffix}', f'{base_path}/y_train{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/ids_train{suffix}', f'{base_path}/ids_train{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/X_cal{suffix}', f'{base_path}/X_cal{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/y_cal{suffix}', f'{base_path}/y_cal{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/ids_cal{suffix}', f'{base_path}/ids_cal{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/X_test{suffix}', f'{base_path}/X_test{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/y_test{suffix}', f'{base_path}/y_test{suffix}')\n",
    "        upload_to_gcs(bucket, f'{base_path}/ids_test{suffix}', f'{base_path}/ids_test{suffix}')\n",
    "            \n",
    "def get_model_multilabel(num_days, num_features):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(num_days, num_features)))\n",
    "    model.add(Dense(3, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy','AUC','Recall', 'Precision'])\n",
    "    return model\n",
    "\n",
    "def get_model_multiclass(num_days, num_features):\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, input_shape=(num_days, num_features)))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy','AUC','Recall', 'Precision'])\n",
    "    return model\n",
    "\n",
    "def save_model_to_gcs(local_model_path, gcs_model_path):\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket_name = gcs_model_path.split('/')[2]\n",
    "    relative_path = '/'.join(gcs_model_path.split('/')[3:])\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(relative_path)\n",
    "    blob.upload_from_filename(local_model_path)\n",
    "    print(f\"Model saved to GCS: {gcs_model_path}\")\n",
    "\n",
    "def load_model_from_gcs(gcs_model_path, local_model_path):\n",
    "    import os\n",
    "    import tensorflow as tf\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket_name = gcs_model_path.split('/')[2]\n",
    "    relative_path = '/'.join(gcs_model_path.split('/')[3:])\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(relative_path)\n",
    "    blob.download_to_filename(local_model_path)\n",
    "    print(f\"Model downloaded from GCS: {gcs_model_path}\")\n",
    "    return tf.keras.models.load_model(local_model_path)\n",
    "\n",
    "def train_model(model, X, y, class_weights, X_val, y_val, local_model_path, gcs_model_path):\n",
    "    from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(local_model_path, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "    model.fit(X, y, epochs=50, validation_data=(X_val, y_val), \n",
    "              class_weight={index: value for index, value in enumerate(class_weights)},\n",
    "              callbacks=[early_stopping, model_checkpoint, lr_scheduler])\n",
    "    \n",
    "    # Save the model to GCS\n",
    "    save_model_to_gcs(local_model_path, gcs_model_path)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# def train_model(model, X, y, class_weights):\n",
    "#     model.fit(X, \n",
    "#               y, \n",
    "#               epochs=5, \n",
    "#               class_weight={index: value for index, value in enumerate(class_weights)})\n",
    "#     return model\n",
    "\n",
    "def convert_multilabel_to_multiclass(y_multilabel):\n",
    "    # Define the mapping from multilabel to multiclass\n",
    "    mapping = {\n",
    "        (1, 0, 0): 0,\n",
    "        (1, 1, 0): 1,\n",
    "        (0, 1, 0): 2,\n",
    "        (0, 0, 1): 3\n",
    "    }\n",
    "    y_multiclass = [mapping[tuple(label)] for label in y_multilabel]\n",
    "    return np.array(y_multiclass)\n",
    "\n",
    "def convert_multilabel_to_multiclass_ohe(y_multilabel):\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    y_multiclass = convert_multilabel_to_multiclass(y_multilabel)\n",
    "    \n",
    "    # One-hot encode the multiclass labels\n",
    "    y_ohe = to_categorical(y_multiclass)\n",
    "    return np.array(y_ohe)\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "# Custom wrapper to make the Keras model compatible with scikit-learn and MAPIE/etc.\n",
    "class KerasMultiLabelWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        if X and y:                 # call fit() with no parameters if underlying model is already fit\n",
    "            self.model.fit(X, y, epochs=5, batch_size=32, verbose=2)\n",
    "        self.classes_ = np.array([0, 1])  # Binary classes\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        proba = self.model.predict(X)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Custom wrapper to make the Keras model compatible with scikit-learn and MAPIE/etc.\n",
    "class KerasMultiClassWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, X=None, y=None):\n",
    "        if X and y:                 # call fit() with no parameters if underlying model is already fit\n",
    "            self.model.fit(X, y, epochs=5, batch_size=32, verbose=2)\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        proba = self.model.predict(X)\n",
    "        return tf.one_hot(tf.argmax(proba, axis=1), depth=proba.shape[-1]).numpy().astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        return self.model.predict(X)\n",
    "\n",
    "def wrap_model_multilabel(model):\n",
    "    return KerasMultiLabelWrapper(model=model).fit()\n",
    "\n",
    "def wrap_model_multiclass(model):\n",
    "    return KerasMultiClassWrapper(model=model).fit()\n",
    "\n",
    "def calibrate_multilabel(all_probabilities, all_targets, nonconformity):\n",
    "    \"\"\"\n",
    "    Calibrate nonconformity scores for multilabel classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_probabilities : np.ndarray\n",
    "        Predicted probabilities for each label. \n",
    "    all_targets : np.ndarray\n",
    "        True class labels.\n",
    "    nonconformity : function\n",
    "        Function to compute nonconformity scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lbl_idx_to_alphas_tuple : dict\n",
    "        Dictionary mapping each label index to its nonconformity scores (negative and positive).\n",
    "    \"\"\"\n",
    "    alphas = np.ones_like(all_probabilities)\n",
    "    for i in range(all_probabilities.shape[0]):\n",
    "        for j in range(all_probabilities.shape[-1]):\n",
    "            alphas[i][j] = nonconformity(all_probabilities[i], j)\n",
    "            \n",
    "    # dictionary of alphas for each label/column\n",
    "    lbl_idx_to_alphas_tuple = {}\n",
    "    for label_idx in range(alphas.shape[-1]):\n",
    "        true_labels = all_targets[:, label_idx].astype(bool)\n",
    "        label_alphas = alphas[:, label_idx]\n",
    "        \n",
    "        # get alphas where true class is negative/positive case, respectively\n",
    "        alpha_neg = 1-label_alphas[~true_labels]\n",
    "        alpha_pos = label_alphas[true_labels]\n",
    "        \n",
    "        lbl_idx_to_alphas_tuple[label_idx] = (alpha_neg, alpha_pos)\n",
    " \n",
    "    return lbl_idx_to_alphas_tuple\n",
    "\n",
    "def calibrate_multiclass(all_probabilities, all_targets, nonconformity):\n",
    "    \"\"\"\n",
    "    Calibrate nonconformity scores for multiclass classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_probabilities : np.ndarray\n",
    "        Predicted probabilities for each class.\n",
    "    all_targets : np.ndarray\n",
    "        True class labels. Can be 1D array of class indices or 2D one-hot encoded.\n",
    "    nonconformity : function\n",
    "        Function to compute nonconformity scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lbl_idx_to_alphas : dict\n",
    "        Dictionary mapping each class label to its nonconformity scores.\n",
    "    \"\"\"\n",
    "    # Check if all_targets is one-hot encoded and convert if necessary\n",
    "    if all_targets.ndim == 2:\n",
    "        all_targets = np.argmax(all_targets, axis=1)\n",
    "    \n",
    "    alphas = np.ones_like(all_probabilities)\n",
    "    for i in range(all_probabilities.shape[0]):\n",
    "        for j in range(all_probabilities.shape[-1]):\n",
    "            alphas[i, j] = nonconformity(all_probabilities[i], j)\n",
    "    \n",
    "    lbl_idx_to_alphas = {}\n",
    "    for label_idx in range(alphas.shape[1]):\n",
    "        true_labels = all_targets == label_idx\n",
    "        label_alphas = alphas[:, label_idx]\n",
    "        \n",
    "        # Get the nonconformity scores for examples where current idx is y_true\n",
    "        lbl_idx_to_alphas[label_idx] = label_alphas[true_labels]\n",
    " \n",
    "    return lbl_idx_to_alphas\n",
    "\n",
    "def conformal_prediction_multilabel(pred, alpha_dict, class_conditional, nonconformity):\n",
    "    n_examples, n_labels = pred.shape\n",
    "    prediction_results = []\n",
    "    \n",
    "    for i in range(n_examples):\n",
    "        example_results = []\n",
    "        for lbl in range(n_labels):\n",
    "            a_neg, a_pos = alpha_dict[lbl]\n",
    "            p = pred[i, lbl]\n",
    "            p_binary = [1-p, p]\n",
    "            \n",
    "            if class_conditional:\n",
    "                example_results.append(PredictionClass([\n",
    "                    ((sum(a_neg >= nonconformity(probs=p_binary, target_idx=0)) + 1) / (len(a_neg) + 1), 0),\n",
    "                    ((sum(a_pos >= nonconformity(probs=p_binary, target_idx=1)) + 1) / (len(a_pos) + 1), 1)\n",
    "                ], eps=0.1))\n",
    "            else:\n",
    "                a = np.concatenate((a_neg, a_pos))\n",
    "                example_results.append(PredictionClass([\n",
    "                    ((sum(a >= nonconformity(p_binary, target_idx=0)) + 1) / (len(a) + 1), 0),\n",
    "                    ((sum(a >= nonconformity(p_binary, target_idx=1)) + 1) / (len(a) + 1), 1)\n",
    "                ], eps=0.1))\n",
    "        \n",
    "        prediction_results.append(example_results)\n",
    "    \n",
    "    return prediction_results\n",
    "\n",
    "def conformal_prediction_multiclass(pred, alpha_dict, class_conditional, nonconformity):\n",
    "    \"\"\"\n",
    "    Perform conformal prediction for multiclass classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : np.ndarray\n",
    "        Predicted probabilities for each class.\n",
    "    alpha_dict : dict\n",
    "        Dictionary mapping each class label to its nonconformity scores.\n",
    "    class_conditional : bool\n",
    "        Whether to use class-conditional calibration nonconformity scores.\n",
    "    nonconformity : function\n",
    "        Function to compute nonconformity scores.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prediction_results : list\n",
    "        List of PredictionClass instances for each example.\n",
    "    \"\"\"\n",
    "    n_examples, n_labels = pred.shape\n",
    "    prediction_results = []\n",
    "\n",
    "    for i in range(n_examples):\n",
    "        example_results = []\n",
    "        for lbl in range(n_labels):\n",
    "            if class_conditional:\n",
    "                lbl_alphas = alpha_dict[lbl]\n",
    "                p_value = (sum(lbl_alphas >= nonconformity(probs=pred[i], target_idx=lbl)) + 1) / (len(lbl_alphas) + 1)\n",
    "            else:\n",
    "                all_alphas = np.concatenate(list(alpha_dict.values()))\n",
    "                p_value = (sum(all_alphas >= nonconformity(probs=pred[i], target_idx=lbl)) + 1) / (len(all_alphas) + 1)\n",
    "                \n",
    "            example_results.append((p_value, lbl))\n",
    "\n",
    "        prediction_results.append(PredictionClass(example_results, eps=0.1))\n",
    "\n",
    "    return prediction_results\n",
    "\n",
    "def flatten_results_multilabel(prediction_set):\n",
    "    return [\n",
    "        (example_idx, label_idx, prediction)\n",
    "        for example_idx, example_results in enumerate(prediction_set)\n",
    "        for label_idx, prediction in enumerate(example_results)\n",
    "    ]\n",
    "\n",
    "def flatten_results_multiclass(prediction_set):\n",
    "    return [\n",
    "        (example_idx, prediction)\n",
    "        for example_idx, prediction in enumerate(prediction_set)\n",
    "    ]\n",
    "\n",
    "####\n",
    "\n",
    "def combine_and_flatten_results(run_results):\n",
    "    combined_results = []\n",
    "\n",
    "    for run_idx, (flattened_results, y_test, y_pred_probs_test, ids_test) in enumerate(run_results):\n",
    "        multilabel = True if len(flattened_results[0]) == 3 else False\n",
    "        \n",
    "        if multilabel:\n",
    "            for example_idx, label_idx, prediction in flattened_results:\n",
    "                combined_results.append({\n",
    "                    \"run\": run_idx,\n",
    "                    \"example_idx\": example_idx,\n",
    "                    \"label_idx\": label_idx,\n",
    "                    \"prediction\": prediction,\n",
    "                    \"y_true\": y_test[example_idx, label_idx],\n",
    "                    \"y_pred_prob_base_clf\": y_pred_probs_test[example_idx, label_idx],\n",
    "                    \"person_id\": ids_test[example_idx]\n",
    "                })\n",
    "        else:\n",
    "            # Check if all_targets is one-hot encoded and convert if necessary\n",
    "            if y_test.ndim == 2:\n",
    "                y_test = np.argmax(y_test, axis=1)\n",
    "                \n",
    "            for example_idx, prediction in flattened_results:\n",
    "                combined_results.append({\n",
    "                    \"run\": run_idx,\n",
    "                    \"example_idx\": example_idx,\n",
    "                    \"prediction\": prediction,\n",
    "                    \"y_true\": y_test[example_idx],\n",
    "                    \"y_pred_prob_base_clf\": y_pred_probs_test[example_idx],\n",
    "                    \"person_id\": ids_test[example_idx]\n",
    "                })\n",
    "\n",
    "    return combined_results\n",
    "\n",
    "def conformal_pred_and_alpha_str_to_tuple(row):\n",
    "    import ast\n",
    "    return ast.literal_eval(row.conformal_pred_and_alpha)\n",
    "\n",
    "def y_pred_prob_base_clf_str_to_array(row):\n",
    "    s = row.y_pred_prob_base_clf\n",
    "    if isinstance(s, float):\n",
    "        return s\n",
    "    \n",
    "    s = s.strip('[')\n",
    "    s = s.strip(']')\n",
    "    return np.array([float(p) for p in s.split()])\n",
    "    \n",
    "def prediction_p_str_to_tuple_list(row):\n",
    "    import ast\n",
    "    return ast.literal_eval(row.prediction_p)\n",
    "\n",
    "def prediction_p_to_prediction(row):\n",
    "    if type(row.prediction_p) is str:\n",
    "        return PredictionClass(p=prediction_p_str_to_tuple_list(row), eps=0.1)\n",
    "    else:\n",
    "        return PredictionClass(p=row.prediction_p, eps=0.1)\n",
    "\n",
    "def calculate_confidence_and_credibility(df):\n",
    "    df['confidence'] = df.apply((lambda row: row.prediction.confidence()), axis=1)\n",
    "    df['credibility'] = df.apply((lambda row: row.prediction.credibility()), axis=1)\n",
    "    return df\n",
    "\n",
    "def get_underlying_classifier_prediction_multiclass(df):\n",
    "    return df['y_pred_prob_base_clf'].apply((lambda x: np.argmax(x)))\n",
    "\n",
    "def get_underlying_classifier_prediction_multilabel(df):\n",
    "    return df['y_pred_prob_base_clf'].apply((lambda x: int(x >= 0.5)))\n",
    "\n",
    "def set_allowable_error_and_update_cp(df, alpha):\n",
    "    def set_eps(pred, eps):\n",
    "        pred.eps = eps\n",
    "        return pred\n",
    "    df['prediction'].apply((lambda x: set_eps(x, alpha)))\n",
    "    df['conformal_pred_and_alpha'] = df['prediction'].apply((lambda x: (x.classes(alpha), alpha)))\n",
    "\n",
    "def results_list_to_df(results, get_underlying_classifier_prediction_fn):\n",
    "    # Convert to a DataFrame for easier analysis\n",
    "    results_df = pd.DataFrame(combine_and_flatten_results(results))\n",
    "\n",
    "    results_df['base_clf_pred'] = get_underlying_classifier_prediction_fn(results_df)\n",
    "    \n",
    "    # store `prediction.p` to allow re-instantiating PredictionClass upon read from CSV\n",
    "    results_df['prediction_p'] = results_df['prediction'].apply((lambda x: x.p))\n",
    "    \n",
    "    alpha = 0.1\n",
    "    results_df['conformal_pred_and_alpha'] = results_df['prediction'].apply((lambda x: (x.classes(alpha), alpha)))\n",
    "    \n",
    "    # Add confidence and credibility\n",
    "    results_df = calculate_confidence_and_credibility(results_df)\n",
    "\n",
    "    # combine w/demographics\n",
    "    results_df = results_df.merge(demo_df, on='person_id',how='left')\n",
    "    \n",
    "    cols = ['run', 'example_idx', 'person_id', \n",
    "            'y_true', 'base_clf_pred', 'conformal_pred_and_alpha', 'confidence', 'credibility', 'prediction_p', \n",
    "            'gender', 'race', 'ethnicity', 'sex_at_birth', 'age', 'prediction', 'y_pred_prob_base_clf'] \n",
    "    \n",
    "    if results_df.columns.str.contains('label_idx').any():\n",
    "        cols.insert(2, 'label_idx')\n",
    "    \n",
    "    results_df = results_df[cols]\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "def results_list_to_df_multilabel(results):\n",
    "    return results_list_to_df(results, get_underlying_classifier_prediction_multilabel)\n",
    "\n",
    "def results_list_to_df_multiclass(results):\n",
    "    return results_list_to_df(results, get_underlying_classifier_prediction_multiclass)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def results_to_df_mapie_multilabel(results):\n",
    "    # Flatten and organize data\n",
    "    flattened_data = []\n",
    "\n",
    "    for run_idx, (y_true, y_pred_probs_base_clf, person_id, crc, rcps, ltt) in enumerate(results):\n",
    "        for example_idx in range(y_true.shape[0]):\n",
    "            for label_idx in range(y_true.shape[1]):\n",
    "                flattened_data.append({\n",
    "                    'run': run_idx,\n",
    "                    'example_idx': example_idx,\n",
    "                    'label_idx': label_idx,\n",
    "                    'crc': crc[example_idx, label_idx],\n",
    "                    'rcps': rcps[example_idx, label_idx],\n",
    "                    'ltt': ltt[example_idx, label_idx],\n",
    "                    'y_true': y_true[example_idx, label_idx],\n",
    "                    'y_pred_prob_base_clf': y_pred_probs_base_clf[example_idx, label_idx],\n",
    "                    'person_id': person_id[example_idx]\n",
    "                })\n",
    "\n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "def results_to_df_mapie_multiclass(results):\n",
    "    # Flatten and organize data\n",
    "    flattened_data = []\n",
    "\n",
    "    for run_idx, (y_true, y_pred_probs_base_clf, person_id, lac, aps, raps, topk) in enumerate(results):\n",
    "        for example_idx in range(y_true.shape[0]):\n",
    "#             for label_idx in range(y_true.shape[1]):\n",
    "            flattened_data.append({\n",
    "                'run': run_idx,\n",
    "                'example_idx': example_idx,\n",
    "#                 'label_idx': label_idx,\n",
    "                'lac': np.where(lac[example_idx])[0],\n",
    "                'aps': np.where(aps[example_idx])[0],\n",
    "                'raps': np.where(raps[example_idx])[0],\n",
    "                'top_k': np.where(topk[example_idx])[0],\n",
    "                'y_true': y_true[example_idx],\n",
    "                'y_pred_prob_base_clf': y_pred_probs_base_clf[example_idx],\n",
    "                'person_id': person_id[example_idx]\n",
    "            })\n",
    "\n",
    "    # Create DataFrame\n",
    "    return pd.DataFrame(flattened_data)\n",
    "\n",
    "import re\n",
    "def results_csv_to_df_mapie(path):\n",
    "    \n",
    "    # Function to convert the string back to a list of numbers\n",
    "    def convert_to_list(string, type_fn):\n",
    "        # Remove the square brackets, and strip any leading/trailing spaces\n",
    "        string = string.strip('[]').strip()\n",
    "        # Replace multiple spaces with a single space\n",
    "        string = re.sub(r'\\s+', ' ', string)\n",
    "        # Convert the split numbers to type\n",
    "        return [type_fn(num) for num in string.split()]\n",
    "\n",
    "    df = pd.read_csv(path)    \n",
    "    #convert int/float lists back from strings\n",
    "    for col in df.columns[df.dtypes == 'object']:\n",
    "        if col == 'y_pred_prob_base_clf':\n",
    "            df[col] = df[col].apply((lambda x: convert_to_list(x, float)))\n",
    "            #df[col] = df[col].apply(lambda x: np.array([float(a) for a in x.strip('[]').strip().replace('  ', ' ').split(' ')]))\n",
    "        else:\n",
    "            df[col] = df[col].apply((lambda x: convert_to_list(x, int)))\n",
    "            #df[col] = df[col].apply(lambda x: np.array([int(a) for a in x.strip('[]').strip().replace('  ', ' ').split(' ')]))\n",
    "    return df\n",
    "\n",
    "def results_csv_to_df(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['prediction_p'] = df.apply(prediction_p_str_to_tuple_list, axis=1)\n",
    "    df['prediction'] = df.apply(prediction_p_to_prediction, axis=1)\n",
    "    df['conformal_pred_and_alpha'] = df.apply(conformal_pred_and_alpha_str_to_tuple, axis=1)\n",
    "    df['y_pred_prob_base_clf'] = df.apply(y_pred_prob_base_clf_str_to_array, axis=1)\n",
    "    df = calculate_confidence_and_credibility(df)\n",
    "    return df\n",
    "\n",
    "### util start\n",
    "\n",
    "def get_structure_info(obj, level=0):\n",
    "    indent = '  ' * level\n",
    "    if isinstance(obj, dict):\n",
    "        print(f\"{indent}dict with {len(obj)} keys\")\n",
    "        for key, value in obj.items():\n",
    "            print(f\"{indent}  key: {key} -> \", end=\"\")\n",
    "            get_structure_info(value, level + 1)\n",
    "    elif isinstance(obj, list):\n",
    "        print(f\"{indent}list of length {len(obj)}\")\n",
    "        if len(obj) > 0:\n",
    "            get_structure_info(obj[0], level + 1)\n",
    "    elif isinstance(obj, tuple):\n",
    "        print(f\"{indent}tuple of length {len(obj)}\")\n",
    "        if len(obj) > 0:\n",
    "            for i in range(len(obj)):\n",
    "                get_structure_info(obj[i], level + 1)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        print(f\"{indent}ndarray with shape {obj.shape}\")\n",
    "    else:\n",
    "        print(f\"{indent}{type(obj).__name__}\")\n",
    "\n",
    "def compare_code(code1, code2):\n",
    "    \"\"\"\n",
    "    Compare two sets of lines of code and print the differences.\n",
    "\n",
    "    Parameters:\n",
    "    code1 (str): The first set of lines of code.\n",
    "    code2 (str): The second set of lines of code.\n",
    "    \"\"\"\n",
    "    import difflib\n",
    "    code1_lines = code1.strip().splitlines()\n",
    "    code2_lines = code2.strip().splitlines()\n",
    "\n",
    "    diff = difflib.unified_diff(\n",
    "        code1_lines, code2_lines,\n",
    "        fromfile='code1', tofile='code2',\n",
    "        lineterm=''\n",
    "    )\n",
    "\n",
    "    print('\\n'.join(diff))\n",
    "\n",
    "### util end\n",
    "\n",
    "\n",
    "def apply_verdict(row):\n",
    "    return row['prediction'].verdict(row['y_true'])\n",
    "\n",
    "# Function to calculate the ratio of true verdicts per demographic group\n",
    "def calculate_verdict_ratio(df, demographic_col, y_true_condition=None, per_run=False, per_label=False):\n",
    "    # Filter by y_true condition if specified\n",
    "    if y_true_condition is not None:\n",
    "        df = df[df['y_true'] == y_true_condition]\n",
    "\n",
    "    def calc_ratio(group):\n",
    "        verdict_true = group[group['verdict'] == True]\n",
    "        return verdict_true[demographic_col].value_counts() / group[demographic_col].value_counts()\n",
    "\n",
    "    if per_run and per_label:\n",
    "        result = df.groupby(['run', 'label_idx']).apply(calc_ratio).unstack(fill_value=0)\n",
    "    elif per_run:\n",
    "        result = df.groupby('run').apply(calc_ratio).unstack(fill_value=0)\n",
    "    elif per_label:\n",
    "        result = df.groupby('label_idx').apply(calc_ratio).unstack(fill_value=0)\n",
    "    else:\n",
    "        result = calc_ratio(df)\n",
    "\n",
    "    return result\n",
    "\n",
    "def print_y_true_0_1_verdict_ratios(df, demographic_col='gender'):\n",
    "    # Run the calculation for y_true == 1\n",
    "    y_true_1_ratio = calculate_verdict_ratio(df, demographic_col=demographic_col, y_true_condition=1)\n",
    "\n",
    "    # Run the calculation for y_true == 0\n",
    "    y_true_0_ratio = calculate_verdict_ratio(df, demographic_col=demographic_col, y_true_condition=0)\n",
    "\n",
    "    print(\"\\n\\n\\nY True == 1 Ratio:\")\n",
    "    print(y_true_1_ratio)\n",
    "    print(\"\\n\\n\\nY True == 0 Ratio:\")\n",
    "    print(y_true_0_ratio)\n",
    "\n",
    "def calculate_prediction_set_size_total_count(df, eps=0.1):\n",
    "    cp_classes = df['prediction'].apply((lambda p: p.classes(eps=eps)))\n",
    "    return cp_classes.apply(len).sum()\n",
    "\n",
    "# Function to calculate the total count of predicted classes per group\n",
    "def calculate_prediction_set_sizes(df, demographic_col, per_run=False, per_label=False, allowable_error_rate=0.1):\n",
    "    eps=allowable_error_rate\n",
    "    def get_prediction_set_size(row):\n",
    "        return len(row['prediction'].classes(eps=eps))\n",
    "\n",
    "    # Calculate the size of the prediction set for each row\n",
    "    col = f'prediction_set_size__at_eps_{str(eps)}'\n",
    "    df[col] = df.apply(get_prediction_set_size, axis=1)\n",
    "\n",
    "    if per_run and per_label:\n",
    "        result = (df.groupby(['run', 'label_idx', demographic_col])[col].sum() / \n",
    "                  df[['run', 'label_idx', demographic_col]].groupby(['run', 'label_idx']).value_counts()).unstack(fill_value=0)\n",
    "    elif per_run:\n",
    "        result = (df.groupby(['run', demographic_col])[col].sum() / \n",
    "                  df[['run', demographic_col]].groupby('run').value_counts()).unstack(fill_value=0)\n",
    "    elif per_label:\n",
    "        result = (df.groupby(['label_idx', demographic_col])[col].sum() / \n",
    "                  df[['label_idx', demographic_col]].groupby('label_idx').value_counts()).unstack(fill_value=0)\n",
    "    else:\n",
    "        result = df.groupby(demographic_col)[col].sum() / df[demographic_col].value_counts()\n",
    "\n",
    "    return result    \n",
    "\n",
    "\n",
    "#### ~/vigilant-computing-machine\n",
    "\n",
    "def sort_reindex(df_pred, col=['confidence','credibility']):\n",
    "    '''\n",
    "    Sort df by the provided column(s), update index to sorted order\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_pred : 'pandas.DataFrame'\n",
    "        A dataframe to be sorted by the provided columns.\n",
    "    col : list, optional\n",
    "        Column(s) to sort from left to right. \n",
    "        The default is ['confidence','credibility'].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    'pandas.DataFrame'\n",
    "        The sorted and reindexed dataframe.\n",
    "\n",
    "    '''\n",
    "    if isinstance(col, str):\n",
    "        return df_pred.sort_values(by=col, ascending=False, kind='mergesort').reset_index(drop=True)\n",
    "    if isinstance(col, list):\n",
    "        return df_pred.sort_values(by=col, ascending=[False]*len(col), kind='mergesort').reset_index(drop=True)\n",
    "\n",
    "def plot_confidence_credibility_by_index(df_pred, title='', ax=None, alpha=1.0, legend=True):\n",
    "    '''\n",
    "    Plot 'confidence' and 'credibility' columns of dataframe by index\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_pred : 'pandas.DataFrame'\n",
    "        dataframe to plot.\n",
    "    title : string, optional\n",
    "        plot title. The default is ''.\n",
    "    ax : 'matplotlib.pyplot.axis', optional\n",
    "        axis to plot on. The default is None.\n",
    "    alpha : float, optional\n",
    "        alpha value of lines. The default is 1.0.\n",
    "    legend : bool, optional\n",
    "        display legend in graph. The default is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    df_pred.plot(y=['confidence', 'credibility'], use_index=True, title=title, ax=ax, alpha=alpha, legend=legend)\n",
    "    ax.set_ylabel('Score')\n",
    "    \n",
    "def plot_conf_cred(df_pred, title='', scale=True, ax=None, alpha=1.0, legend=True):\n",
    "    '''\n",
    "    Plot df sorted and indexed by 'confidence' and 'credibility'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_pred : 'pandas.DataFrame'\n",
    "        dataframe to plot.\n",
    "    title : string, optional\n",
    "        plot title. The default is ''.\n",
    "    scale : bool, optional\n",
    "        scale plot. The default is True.\n",
    "    ax : 'matplotlib.pyplot.axis', optional\n",
    "        axis to plot on. The default is None.\n",
    "    alpha : float, optional\n",
    "        alpha value of lines. The default is 1.0.\n",
    "    legend : bool, optional\n",
    "        display legend in graph. The default is True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    df = sort_reindex(df_pred, ['confidence', 'credibility'])\n",
    "    if scale:\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        df[['confidence', 'credibility']] = scaler.fit_transform(df[['confidence', 'credibility']])\n",
    "    plot_confidence_credibility_by_index(df, title=title, ax=ax, alpha=alpha, legend=legend)\n",
    "\n",
    "def plot_conf_cred_2(df1, df2, title1='Class-Conditional', title2='Non-Class-Conditional'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 15))\n",
    "    \n",
    "    # Plot class-conditional data\n",
    "    axs[0].vlines(x=len(df1) * .9, ymin=0, ymax=1, linestyle='--', label='LDR', color='g', linewidth=1)\n",
    "    plot_conf_cred(df1, title=title1, alpha=0.4, ax=axs[0], scale=False)\n",
    "    axs[0].set_title(title1)\n",
    "    axs[0].set_ylabel('Score')\n",
    "    axs[0].legend()\n",
    "    \n",
    "    # Plot non-class-conditional data\n",
    "    axs[1].vlines(x=len(df2) * .9, ymin=0, ymax=1, linestyle='--', label='LDR', color='g', linewidth=1)\n",
    "    plot_conf_cred(df2, title=title2, alpha=0.4, ax=axs[1], scale=False)\n",
    "    axs[1].set_title(title2)\n",
    "    axs[1].set_ylabel('Score')\n",
    "    axs[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#### ~/vigilant-computing-machine\n",
    "\n",
    "def is_y_true_in_cp(df):\n",
    "    return df.apply((lambda row: row['y_true'] in row['conformal_pred_and_alpha'][0]), axis=1)\n",
    "\n",
    "def calculate_y_true_in_cp_percent(df, per_run=False):\n",
    "    if per_run:\n",
    "        return df.groupby('run').apply(calculate_y_true_in_cp_percent)\n",
    "    else:\n",
    "        return is_y_true_in_cp(df).sum() / len(df)\n",
    "\n",
    "def is_y_true_same_as_base_clf_pred(df):\n",
    "    return df.apply((lambda row: row['y_true'] == row['base_clf_pred']), axis=1) \n",
    "\n",
    "def calculate_y_true_same_as_base_clf_pred_percent(df, per_run=False):\n",
    "    if per_run:\n",
    "        return df.groupby('run').apply(calculate_y_true_same_as_base_clf_pred_percent)\n",
    "    else:\n",
    "        return is_y_true_same_as_base_clf_pred(df).sum() / len(df)    \n",
    "    \n",
    "# TODO per label/run/etc. grouping and conditions\n",
    "\n",
    "def print_base_clf_report_multiclass(df, labels=None):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    y = df['y_true'].values\n",
    "    base_clf_pred = df['base_clf_pred'].values\n",
    "    print(classification_report(y, base_clf_pred, target_names=labels))\n",
    "\n",
    "def print_base_clf_report_multilabel(df, labels=None):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    ys = []\n",
    "    preds = []\n",
    "    for grp, grp_df in df.groupby(['run','example_idx']):\n",
    "        ys.append(grp_df['y_true'].values)\n",
    "        preds.append(grp_df['base_clf_pred'].values)\n",
    "\n",
    "    print(classification_report(np.array(ys), np.array(preds), target_names=labels))\n",
    "    del ys\n",
    "    del preds\n",
    "\n",
    "def print_base_clf_report_multilabel_binary(df, labels=None):\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    for grp, grp_df in results_name_df_tuples[10][1].groupby('label_idx'):\n",
    "        print(f'-----------------\\nLabel: {grp if labels is None else labels[grp]}'+\n",
    "              f'  - present {grp_df.y_true.sum() / len(grp_df) * 100:.1f}% of patients\\n-----------------')\n",
    "        print_base_clf_report_multiclass(grp_df, ['Disorder  Absent', 'Disorder Present'])\n",
    "\n",
    "        \n",
    "def get_exp_rep_table(df, demographic_col='gender'):\n",
    "    sample_size = len(df)\n",
    "\n",
    "    n = df[demographic_col].value_counts().sort_index()\n",
    "    nr = n.values.sum()\n",
    "    d = pd.DataFrame()\n",
    "    d[f'all_{demographic_col}_n'] = n\n",
    "    d[f'all_{demographic_col}'] = n / nr\n",
    "\n",
    "    lc = get_low_confidence_predictions(df, 10)\n",
    "    n = lc[demographic_col].value_counts().sort_index()\n",
    "    nr = n.values.sum()\n",
    "    d[f'low_{demographic_col}_n'] = n\n",
    "    d[f'low_{demographic_col}'] = n / nr\n",
    "    d = d.fillna(0)\n",
    "    d[f'low_{demographic_col}_n'] = d[f'low_{demographic_col}_n'].astype(int)\n",
    "    return d\n",
    "\n",
    "def get_low_confidence_predictions(df, percentile=10):\n",
    "    #check valid range\n",
    "    assert 0 < percentile and percentile < 100, 'percentile outside valid range'\n",
    "    if percentile < 1:\n",
    "        percentile = percentile * 100\n",
    "    #integer math rounds down, preventing rounding up beyond bounds for small collections (though .head() handles)\n",
    "    #open to reasons to round up\n",
    "    num_to_return = len(df) // percentile\n",
    "    #when predictions with the same confidence value span the percentile boundary,\n",
    "    #credibility will be used as the secondary sort criteria\n",
    "    #when predictions with the same confidence and credibility span the percentile boundary,\n",
    "    #predictions will be returned based upon their index values in the provided DataFrame\n",
    "    df = df.sort_values(by=['confidence', 'credibility'], kind='mergesort')\n",
    "    return df.iloc[:num_to_return, :]\n",
    "\n",
    "def get_low_credibility_predictions(df, percentile=10):\n",
    "    #check valid range\n",
    "    assert 0 < percentile and percentile < 100, 'percentile outside valid range'\n",
    "    if percentile < 1:\n",
    "        percentile = percentile * 100\n",
    "    #integer math rounds down, preventing rounding up beyond bounds for small collections (though .head() handles)\n",
    "    #open to reasons to round up\n",
    "    num_to_return = len(df) // percentile\n",
    "    #when predictions with the same credibility value span the percentile boundary,\n",
    "    #confidence will be used as the secondary sort criteria\n",
    "    #when predictions with the same confidence and credibility span the percentile boundary,\n",
    "    #predictions will be returned based upon their index values in the provided DataFrame\n",
    "    df = df.sort_values(by=['credibility', 'confidence'], kind='mergesort')\n",
    "    return df.iloc[:num_to_return, :]\n",
    "\n",
    "def get_experiments_max_low_confidence(experiments):\n",
    "    return [get_low_confidence_predictions(exp.df[0], percentile=10).confidence.max() for exp in experiments]\n",
    "\n",
    "def get_experiments_max_low_credibility(experiments):\n",
    "    return [get_low_credibility_predictions(exp.df[0], percentile=10).credibility.max() for exp in experiments]\n",
    "\n",
    "def get_experiments_median_low_credibility(experiments):\n",
    "    return [get_low_credibility_predictions(exp.df[0], percentile=10).credibility.median() for exp in experiments]\n",
    "\n",
    "def get_incorrect_predictions(df):\n",
    "    return df[~df['verdict']]\n",
    "\n",
    "def get_empty_predictions_mask(df):\n",
    "    return df.classes.apply((lambda x: len(x) == 0))\n",
    "\n",
    "def get_single_predictions_mask(df):\n",
    "    return df.classes.apply((lambda x: len(x) == 1))\n",
    "\n",
    "def get_multiple_predictions_mask(df):\n",
    "    return df.classes.apply((lambda x: len(x) > 1))\n",
    "\n",
    "def df_col_to_int_if_float_is_integer_all(df, col_name):\n",
    "    '''\n",
    "    Coerce df column to int if all are float where float.is_integer == True\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 'pandas.DataFrame'\n",
    "        dataframe containing column to potentially coerce to int.\n",
    "    col_name : string\n",
    "        name of column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # if all instances in this column are integers in float representation\n",
    "    if df.loc[:,col_name].apply(float.is_integer).all():\n",
    "        # convert all instances in this column to integer\n",
    "        df.loc[:,col_name] = df.loc[:,col_name].astype(int)\n",
    "\n",
    "def df_pred_empty_mean(df, pred_col_name='classes'):\n",
    "    '''\n",
    "    Calculate the proportion of predictions \n",
    "    (generally, could be any column containing a type that can have len() applied) \n",
    "    that are empty.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 'pandas.DataFrame'\n",
    "        dataframe containing predictions.\n",
    "    pred_col_name : string, optional\n",
    "        column name. The default is 'classes'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        proportion of empty entries.\n",
    "\n",
    "    '''\n",
    "    return df[pred_col_name].apply(lambda x: len(x) < 1).mean()\n",
    "\n",
    "def df_pred_singleton_mean(df, pred_col_name='classes'):\n",
    "    '''\n",
    "    Calculate the proportion of predictions \n",
    "    (generally, could be any column containing a type that can have len() applied) \n",
    "    that are of length 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 'pandas.DataFrame'\n",
    "        dataframe containing predictions.\n",
    "    pred_col_name : string, optional\n",
    "        column name. The default is 'classes'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        proportion of singleton entries.\n",
    "\n",
    "    '''\n",
    "    return df[pred_col_name].apply(lambda x: len(x)==1).mean()\n",
    "\n",
    "def df_pred_singleton_correct_mean(df, pred_col_name='classes', verdict_col_name='verdict'):\n",
    "    '''\n",
    "    Calculate the proportion of predictions that are of length 1 and contain \n",
    "    the correct class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 'pandas.DataFrame'\n",
    "        dataframe containing predictions and verdicts.\n",
    "    pred_col_name : string, optional\n",
    "        prediction column name. The default is 'classes'.\n",
    "    verdict_col_name : string, optional\n",
    "        verdict column name. The default is 'verdict'.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        proportion of singleton entries that correspond to the correct class.\n",
    "\n",
    "    '''\n",
    "    single_and_correct = (df[pred_col_name].apply(lambda x: len(x)==1) & df[verdict_col_name])\n",
    "    return sum(single_and_correct) / len(df)\n",
    "\n",
    "def df_pred_multiple_mean(df, pred_col_name='classes'):\n",
    "    '''\n",
    "    \n",
    "\n",
    "    Calculate the proportion of predictions \n",
    "    (generally, could be any column containing a type that can have len() applied) \n",
    "    that are of length greater than 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : 'pandas.DataFrame'\n",
    "        dataframe containing predictions.\n",
    "    pred_col_name : string, optional\n",
    "        column name. The default is 'classes'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        proportion of multiple entries.\n",
    "\n",
    "    '''\n",
    "    return df[pred_col_name].apply(lambda x: len(x) > 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `run_experiment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:21.695553Z",
     "iopub.status.busy": "2024-08-15T01:45:21.694997Z",
     "iopub.status.idle": "2024-08-15T01:45:21.713907Z",
     "shell.execute_reply": "2024-08-15T01:45:21.712919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_experiment(daily_df,\n",
    "                   demographic_df,\n",
    "                   label_df,\n",
    "                   get_model_fn, \n",
    "                   train_model_fn,\n",
    "                   wrap_model_fn,\n",
    "                   nonconformity_fn,\n",
    "                   calibrate_fn,\n",
    "                   conformal_prediction_fn,\n",
    "                   class_conditional,\n",
    "                   flatten_results_fn,\n",
    "                   times=10, \n",
    "                   num_days=10,\n",
    "                   model_name_suffix=''):\n",
    "    \n",
    "    use_demographics = demographic_df is not None\n",
    "    \n",
    "    run_flattenedResult_yTrue_yPredProbs_personId = []\n",
    "    \n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    \n",
    "    for i in range(times):\n",
    "        \n",
    "        # reproducible experimental variability\n",
    "        set_seeds(offset=i)\n",
    "        \n",
    "         # Determine the model type (multilabel or multiclass) based on the get_model_fn\n",
    "        model_type = 'multilabel' if get_model_fn.__name__.startswith('get_model_multilabel') else 'multiclass'\n",
    "        model_type += '_with_demo' if use_demographics else '_wout_demo'\n",
    "        \n",
    "        # Define the base path for the experiment\n",
    "        base = f'data/experiments/{i}'\n",
    "        base_path = f'{my_bucket}/{base}'\n",
    "        gcs_model_path = f'{base_path}/{model_type}/best_model_{i}_{str(num_days)}_day_seqs'+model_name_suffix+'.h5'\n",
    "        local_model_path = f'{base}/{model_type}/best_model_{i}_{str(num_days)}_day_seqs'+model_name_suffix+'.h5'\n",
    "        \n",
    "        # Create local directories if they don't exist\n",
    "        os.makedirs(os.path.dirname(local_model_path), exist_ok=True)\n",
    "        \n",
    "        # load this experiment configurations data, if exists\n",
    "        exists, \\\n",
    "        X_train, X_cal, X_test, \\\n",
    "        y_train, y_cal, y_test, \\\n",
    "        ids_train, ids_cal, ids_test = does_this_experiments_input_data_exist(run_num=i, \n",
    "                                                                              num_days=num_days, \n",
    "                                                                              with_demographics=use_demographics)\n",
    "        \n",
    "        # generate this experiment configurations data, if not exists\n",
    "        if not exists:            \n",
    "            df = get_random_contiguous_chunks_with_no_missing_data(daily_df, \n",
    "                                                                   chunk_size=num_days, \n",
    "                                                                   max_attempts=10)\n",
    "\n",
    "            if use_demographics:\n",
    "                df, categorical_cols = merge_demographics_and_ohe_categorical_columns(df, demographic_df)\n",
    "                \n",
    "            excl_scaling_cols = [*categorical_cols] if use_demographics else []\n",
    "            \n",
    "            (X_train, y_train, ids_train), \\\n",
    "            (X_cal, y_cal, ids_cal), \\\n",
    "            (X_test, y_test, ids_test) = get_scaled_reshaped_train_calibrate_test(df, \n",
    "                                                                                  label_df, \n",
    "                                                                                  num_days=num_days,\n",
    "                                                                                  random_offset=i, \n",
    "                                                                                  exclude_scale_cols=excl_scaling_cols)\n",
    "\n",
    "            # write this experiment configurations data\n",
    "            write_this_experiments_input_data_if_not_exists(i, \n",
    "                                                            num_days, \n",
    "                                                            use_demographics, \n",
    "                                                            X_train, y_train, ids_train, \n",
    "                                                            X_cal, y_cal, ids_cal, \n",
    "                                                            X_test, y_test, ids_test)\n",
    "        \n",
    "        if model_type.startswith('multiclass'):\n",
    "            y_train, y_cal, y_test = convert_multilabel_to_multiclass_ohe(y_train), convert_multilabel_to_multiclass_ohe(y_cal), convert_multilabel_to_multiclass_ohe(y_test)\n",
    "\n",
    "        # Define class weights\n",
    "        label_counts = y_train.sum(axis=0)\n",
    "        print(f'\\n\\nLabel counts (run {i}): {label_counts}\\n')\n",
    "            \n",
    "        # Check if the model already exists\n",
    "        if os.path.exists(local_model_path):\n",
    "            import tensorflow as tf\n",
    "            print(f\"Loading existing model from {local_model_path}\")\n",
    "            mod = tf.keras.models.load_model(local_model_path)\n",
    "        else:\n",
    "            \n",
    "            if storage.Client().bucket(gcs_model_path.split('/')[2]).blob('/'.join(gcs_model_path.split('/')[3:])).exists():\n",
    "                print(f\"Downloading existing model from GCS: {gcs_model_path}\")\n",
    "                mod = load_model_from_gcs(gcs_model_path, local_model_path)\n",
    "            else:\n",
    "                # Get sequence shape\n",
    "                num_days = X_train.shape[1]\n",
    "                num_features = X_train.shape[2]\n",
    "\n",
    "                print(f'num days: {num_days}')\n",
    "                print(f'num features: {num_features}')\n",
    "                \n",
    "                # Define class weights\n",
    "                import tensorflow as tf\n",
    "                class_weights = tf.constant(label_counts.min()/label_counts, dtype=tf.float32)\n",
    "                  ## also tried tf.constant(label_counts.max()/label_counts, dtype=tf.float32), marginal differences observed\n",
    "                \n",
    "                # sanity check loss weighting\n",
    "                print(f'\\n\\nLabel counts (run {i}): {label_counts}\\n'+\n",
    "                      f'Class Weights: {str(class_weights.numpy())}')\n",
    "                \n",
    "                # Get model\n",
    "                mod = get_model_fn(num_days, num_features)\n",
    "                \n",
    "                # Train the model and save it to GCS\n",
    "                mod = train_model_fn(mod, \n",
    "                                     X=X_train, \n",
    "                                     y=y_train, \n",
    "                                     class_weights=class_weights, \n",
    "                                     X_val=X_cal, \n",
    "                                     y_val=y_cal,\n",
    "                                     local_model_path=local_model_path, \n",
    "                                     gcs_model_path=gcs_model_path)\n",
    "            \n",
    "        # wrap\n",
    "        mod = wrap_model_fn(mod)\n",
    "\n",
    "        # predict (calibration)\n",
    "        pred_probs_cal = mod.predict_proba(X_cal)\n",
    "\n",
    "        # get nonconformity scores\n",
    "        lbl_idx_to_alphas = calibrate_fn(pred_probs_cal, y_cal, nonconformity_fn)\n",
    "        \n",
    "        # predict (test)\n",
    "        pred_probs_test = mod.predict_proba(X_test)\n",
    "        \n",
    "        # Conformal Prediction sets\n",
    "        prediction_sets = conformal_prediction_fn(pred_probs_test, \n",
    "                                                  lbl_idx_to_alphas, \n",
    "                                                  class_conditional, \n",
    "                                                  nonconformity_fn)\n",
    "        \n",
    "        # Flatten the results\n",
    "        flattened_results = flatten_results_fn(prediction_sets)\n",
    "        \n",
    "        run_flattenedResult_yTrue_yPredProbs_personId.append([flattened_results, y_test, pred_probs_test, ids_test])\n",
    "        \n",
    "    return run_flattenedResult_yTrue_yPredProbs_personId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## `run_experiment_mapie`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     138,
     2
    ],
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:21.695553Z",
     "iopub.status.busy": "2024-08-15T01:45:21.694997Z",
     "iopub.status.idle": "2024-08-15T01:45:21.713907Z",
     "shell.execute_reply": "2024-08-15T01:45:21.712919Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_experiment_mapie(daily_df,\n",
    "                         demographic_df,\n",
    "                         label_df,\n",
    "                         get_model_fn, \n",
    "                         train_model_fn,\n",
    "                         wrap_model_fn,\n",
    "                         times=10, \n",
    "                         num_days=10):\n",
    "    \n",
    "    use_demographics = demographic_df is not None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    \n",
    "    for i in range(times):\n",
    "        \n",
    "        # reproducible experimental variability\n",
    "        set_seeds(offset=i)\n",
    "        \n",
    "         # Determine the model type (multilabel or multiclass) based on the get_model_fn\n",
    "        model_type = 'multilabel' if get_model_fn.__name__ == 'get_model_multilabel' else 'multiclass'\n",
    "        model_type += '_with_demo' if use_demographics else '_wout_demo'\n",
    "        \n",
    "        # Define the base path for the experiment\n",
    "        base = f'data/experiments/{i}'\n",
    "        base_path = f'{my_bucket}/{base}'\n",
    "        gcs_model_path = f'{base_path}/{model_type}/best_model_{i}_{str(num_days)}_day_seqs.h5'\n",
    "        local_model_path = f'{base}/{model_type}/best_model_{i}_{str(num_days)}_day_seqs.h5'\n",
    "        \n",
    "        # Create local directories if they don't exist\n",
    "        os.makedirs(os.path.dirname(local_model_path), exist_ok=True)\n",
    "        \n",
    "        # load this experiment configurations data, if exists\n",
    "        exists, \\\n",
    "        X_train, X_cal, X_test, \\\n",
    "        y_train, y_cal, y_test, \\\n",
    "        ids_train, ids_cal, ids_test = does_this_experiments_input_data_exist(run_num=i, \n",
    "                                                                              num_days=num_days, \n",
    "                                                                              with_demographics=use_demographics)\n",
    "        \n",
    "        # generate this experiment configurations data, if not exists\n",
    "        if not exists:            \n",
    "            df = get_random_contiguous_chunks_with_no_missing_data(daily_df, \n",
    "                                                                   chunk_size=num_days, \n",
    "                                                                   max_attempts=10)\n",
    "\n",
    "            if use_demographics:\n",
    "                df, categorical_cols = merge_demographics_and_ohe_categorical_columns(df, demographic_df)\n",
    "                \n",
    "            excl_scaling_cols = [*categorical_cols] if use_demographics else []\n",
    "            \n",
    "            (X_train, y_train, ids_train), \\\n",
    "            (X_cal, y_cal, ids_cal), \\\n",
    "            (X_test, y_test, ids_test) = get_scaled_reshaped_train_calibrate_test(df, \n",
    "                                                                                  label_df, \n",
    "                                                                                  num_days=num_days,\n",
    "                                                                                  random_offset=i, \n",
    "                                                                                  exclude_scale_cols=excl_scaling_cols)\n",
    "\n",
    "            # write this experiment configurations data\n",
    "            write_this_experiments_input_data_if_not_exists(i, \n",
    "                                                            num_days, \n",
    "                                                            use_demographics, \n",
    "                                                            X_train, y_train, ids_train, \n",
    "                                                            X_cal, y_cal, ids_cal, \n",
    "                                                            X_test, y_test, ids_test)\n",
    "        is_multilabel = True\n",
    "        if model_type.startswith('multiclass'):\n",
    "            y_train, y_cal, y_test = convert_multilabel_to_multiclass(y_train), convert_multilabel_to_multiclass(y_cal), convert_multilabel_to_multiclass(y_test)\n",
    "            is_multilabel = False\n",
    "\n",
    "        # Define class weights\n",
    "        label_counts = y_train.sum(axis=0)\n",
    "        print(f'\\n\\nLabel counts (run {i}): {label_counts}\\n')\n",
    "            \n",
    "        # Check if the model already exists\n",
    "        if os.path.exists(local_model_path):\n",
    "            import tensorflow as tf\n",
    "            print(f\"Loading existing model from {local_model_path}\")\n",
    "            mod = tf.keras.models.load_model(local_model_path)\n",
    "        else:\n",
    "            \n",
    "            if storage.Client().bucket(gcs_model_path.split('/')[2]).blob('/'.join(gcs_model_path.split('/')[3:])).exists():\n",
    "                print(f\"Downloading existing model from GCS: {gcs_model_path}\")\n",
    "                mod = load_model_from_gcs(gcs_model_path, local_model_path)\n",
    "            else:\n",
    "                # Get sequence shape\n",
    "                num_days = X_train.shape[1]\n",
    "                num_features = X_train.shape[2]\n",
    "\n",
    "                print(f'num days: {num_days}')\n",
    "                print(f'num features: {num_features}')\n",
    "                \n",
    "                # Get model\n",
    "                mod = get_model_fn(num_days, num_features)\n",
    "                \n",
    "                # Define class weights\n",
    "                import tensorflow as tf\n",
    "                class_weights = tf.constant(label_counts.min()/label_counts, dtype=tf.float32)\n",
    "                \n",
    "                # Train the model and save it to GCS\n",
    "                mod = train_model_fn(mod, X=X_train, y=y_train, class_weights=class_weights, X_val=X_cal, y_val=y_cal, local_model_path=local_model_path, gcs_model_path=gcs_model_path)\n",
    "            \n",
    "        # wrap\n",
    "        mod = wrap_model_fn(mod)\n",
    "\n",
    "        if is_multilabel:\n",
    "            # Wrap the model with MapieMultiLabelClassifier\n",
    "            #\n",
    "            #     References\n",
    "            #     ----------\n",
    "            #     [1] Lihua Lei Jitendra Malik Stephen Bates, Anastasios Angelopoulos\n",
    "            #     and Michael I. Jordan. Distribution-free, risk-controlling prediction\n",
    "            #     sets. CoRR, abs/2101.02703, 2021.\n",
    "            #     URL https://arxiv.org/abs/2101.02703.39\n",
    "\n",
    "            #     [2] Angelopoulos, Anastasios N., Stephen, Bates, Adam, Fisch, Lihua,\n",
    "            #     Lei, and Tal, Schuster. \"Conformal Risk Control.\" (2022).\n",
    "\n",
    "            #     [3] Angelopoulos, A. N., Bates, S., Candès, E. J., Jordan,\n",
    "            #     M. I., & Lei, L. (2021). Learn then test:\n",
    "            #     \"Calibrating predictive algorithms to achieve risk control\".\n",
    "            #\n",
    "            #\n",
    "            # valid_methods_by_metric_ = {\n",
    "            #         \"precision\": [\"ltt\"],\n",
    "            #         \"recall\": [\"rcps\", \"crc\"]\n",
    "            #     }\n",
    "            #\n",
    "            # method = \n",
    "            #          'crc'  (Conformal Risk Control) \n",
    "            #          'rcps' (Risk-Controlling Prediction Sets) \n",
    "            #          'ltt'  (Learn-Then-Test)\n",
    "            #\n",
    "\n",
    "            # Conformal Risk Control\n",
    "            crc = MapieMultiLabelClassifier(estimator=mod, \n",
    "                                            metric_control='recall',        # 'recall' -> avoid missing conditions\n",
    "                                            method='crc',                   # recall='crc'/'rcps'\n",
    "                                            n_jobs=-1,                      # default 1 => easier debug; -1 for all CPUs\n",
    "                                            verbose=2,\n",
    "                                            random_state=42+i)\n",
    "\n",
    "            # Risk-Controlled Prediction Sets\n",
    "            rcps = MapieMultiLabelClassifier(estimator=mod, \n",
    "                                             metric_control='recall',        # 'recall' -> avoid missing conditions\n",
    "                                             method='rcps',                  # recall='crc'/'rcps'\n",
    "                                             n_jobs=-1,                      # default 1 => easier debug; -1 for all CPUs\n",
    "                                             verbose=2,\n",
    "                                             random_state=42+i)\n",
    "\n",
    "            # Learn-Then-Test\n",
    "            ltt = MapieMultiLabelClassifier(estimator=mod, \n",
    "                                            metric_control='precision',     # 'precision' -> avoid falsely predicting conditions\n",
    "                                            method='ltt',                   # precision='ltt'\n",
    "                                            n_jobs=-1,                      # default 1 => easier debug; -1 for all CPUs\n",
    "                                            verbose=2,\n",
    "                                            random_state=42+i)\n",
    "\n",
    "            # calibrate conformal methods\n",
    "            crc = crc.partial_fit(X_cal, y_cal, _refit=False)\n",
    "            rcps = rcps.partial_fit(X_cal, y_cal, _refit=False)\n",
    "            ltt = ltt.partial_fit(X_cal, y_cal, _refit=False)\n",
    "\n",
    "\n",
    "            # set acceptable level(s) of error for crc/rcps\n",
    "            error_rates = [0.1]\n",
    "\n",
    "            # the level of certainty at which we compute the Upper Confidence Bound of the average risk.\n",
    "            # Lower `delta` produce larger (more conservative) prediction sets.\n",
    "            #\n",
    "            delta = 0.01      # 99% certainty distinguishes rcps from crc more markedly than 90%\n",
    "\n",
    "            # Make predictions\n",
    "            y_pred, y_pis_crc = crc.predict(X_test, \n",
    "                                            alpha=error_rates)\n",
    "\n",
    "            y_pred, y_pis_rcps = rcps.predict(X_test, \n",
    "                                              alpha=error_rates, \n",
    "                                              delta=delta)\n",
    "\n",
    "            y_pred, y_pis_ltt = ltt.predict(X_test,\n",
    "                                            alpha=[0.5],       # arbitrary user-specified error ~ be right more often than not\n",
    "                                            delta=delta)\n",
    "\n",
    "            # get prediction probabilites of underlying classifier\n",
    "            pred_probs_test = mod.predict_proba(X_test)\n",
    "\n",
    "            # squeeze per only defined single error rate\n",
    "            y_crc, y_rcps, y_ltt = y_pis_crc.squeeze(), y_pis_rcps.squeeze(), y_pis_ltt.squeeze()\n",
    "\n",
    "            run_yTrue_yPredProbs_personIds_crc_rcps_ltt = (y_test, \n",
    "                                                           pred_probs_test, \n",
    "                                                           ids_test,\n",
    "                                                           y_crc,\n",
    "                                                           y_rcps,\n",
    "                                                           y_ltt)\n",
    "            \n",
    "            results.append(run_yTrue_yPredProbs_personIds_crc_rcps_ltt)\n",
    "            \n",
    "        else:\n",
    "            # Wrap the model with MapieClassifier\n",
    "            #\n",
    "            #         References\n",
    "            #     ----------\n",
    "            #     [1] Mauricio Sadinle, Jing Lei, and Larry Wasserman.\n",
    "            #     \"Least Ambiguous Set-Valued Classifiers with Bounded Error Levels.\",\n",
    "            #     Journal of the American Statistical Association, 114, 2019.\n",
    "            #\n",
    "            #     [2] Yaniv Romano, Matteo Sesia and Emmanuel J. Candès.\n",
    "            #     \"Classification with Valid and Adaptive Coverage.\"\n",
    "            #     NeurIPS 202 (spotlight) 2020.\n",
    "            #\n",
    "            #     [3] Anastasios Nikolas Angelopoulos, Stephen Bates, Michael Jordan\n",
    "            #     and Jitendra Malik.\n",
    "            #     \"Uncertainty Sets for Image Classifiers using Conformal Prediction.\"\n",
    "            #     International Conference on Learning Representations 2021.\n",
    "            \n",
    "            mod.classes_ = np.unique(np.concatenate([y_train, y_cal, y_test]))\n",
    "            \n",
    "            \n",
    "            methods = [\"lac\", \"aps\", \"raps\", \"top_k\"]\n",
    "            mapie, y_pred_mapie, y_ps_mapie = {}, {}, {}\n",
    "            error_rates = [0.1]\n",
    "            for method in methods:\n",
    "                mapie[method] = MapieClassifier(\n",
    "                    estimator=mod,\n",
    "                    method=method,\n",
    "                    cv=\"prefit\",\n",
    "                    random_state=42+i,\n",
    "                )\n",
    "                mapie[method].fit(X_cal, y_cal)\n",
    "                y_pred_mapie[method], y_ps_mapie[method] = \\\n",
    "                    mapie[method].predict(X_test, \n",
    "                                          alpha=error_rates, \n",
    "                                          include_last_label=True   # per coverage guarantee [3]\n",
    "                                         )\n",
    "            \n",
    "            # get prediction probabilites of underlying classifier\n",
    "            pred_probs_test = mod.predict_proba(X_test)\n",
    "\n",
    "            # squeeze per only defined single error rate\n",
    "            y_lac, y_aps, y_raps, y_topk = (y_ps_mapie['lac'].squeeze(), \n",
    "                                            y_ps_mapie['aps'].squeeze(), \n",
    "                                            y_ps_mapie['raps'].squeeze(),\n",
    "                                            y_ps_mapie['top_k'].squeeze())\n",
    "            \n",
    "            \n",
    "            \n",
    "            run_yTrue_yPredProbs_personIds_lac_aps_raps_topk = (y_test, \n",
    "                                                                pred_probs_test, \n",
    "                                                                ids_test,\n",
    "                                                                y_lac,\n",
    "                                                                y_aps,\n",
    "                                                                y_raps,\n",
    "                                                                y_topk)\n",
    "            \n",
    "            results.append(run_yTrue_yPredProbs_personIds_lac_aps_raps_topk)\n",
    "\n",
    "        \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T01:45:21.718475Z",
     "iopub.status.busy": "2024-08-15T01:45:21.717917Z",
     "iopub.status.idle": "2024-08-15T01:47:35.255750Z",
     "shell.execute_reply": "2024-08-15T01:47:35.254785Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefix = f'{my_bucket}/data/dfs/'\n",
    "\n",
    "# Read CSVs\n",
    "demo_df = pd.read_csv(f\"{prefix}demographics_df.csv\")\n",
    "daily_df = pd.read_csv(f\"{prefix}daily_df_v2_prepped.csv\")\n",
    "labels = pd.read_csv(f\"{prefix}daily_df_labels_v2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Number of Individuals Before Per-Run Fetch of 10-Day Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "13835"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Percent - Multi-Label Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = labels.sum(axis=0)/labels.shape[0]*100\n",
    "for i, v in zip(temp.index,temp):\n",
    "    print(f'{i:<20} {v:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "Anxiety disorder     16.62%\n",
    "Depressive disorder  15.73%\n",
    "No disorder          78.29%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Percent - Multi-Label/Class With Both Anxiety and Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = labels[(labels['Anxiety disorder'] == 1) & (labels['Depressive disorder'] == 1)].shape[0]/labels.shape[0]*100\n",
    "print(f'{temp:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "10.63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Percent - Multi-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = labels[(labels['Anxiety disorder'] == 0) & (labels['Depressive disorder'] == 1)].shape[0]/labels.shape[0]*100\n",
    "print(f'{temp:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5.10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = labels[(labels['Anxiety disorder'] == 1) & (labels['Depressive disorder'] == 0)].shape[0]/labels.shape[0]*100\n",
    "print(f'{temp:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "5.98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = labels[(labels['Anxiety disorder'] == 0) & (labels['Depressive disorder'] == 0)].shape[0]/labels.shape[0]*100\n",
    "print(f'{temp:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "78.29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import MAPIE (Model Agnostic Prediction Interval Estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#clone MAPIE repo\n",
    "!git clone https://github.com/scikit-learn-contrib/MAPIE\n",
    "\n",
    "    \n",
    "#add MAPIE to PYTHONPATH so python can find MAPIE module\n",
    "import sys\n",
    "\n",
    "pwd = !pwd\n",
    "sys.path.append(f'{pwd[0]}/MAPIE')\n",
    "\n",
    "#imports\n",
    "from mapie.multi_label_classification import MapieMultiLabelClassifier\n",
    "from mapie.classification import MapieClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Run Experiment - Multi-Label (`crc`, `rcps`, `ltt`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Include Demographic Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = \\\n",
    "    run_experiment_mapie(daily_df=daily_df,\n",
    "                         demographic_df=demo_df,\n",
    "                         label_df=labels,\n",
    "                         get_model_fn=get_model_multilabel, \n",
    "                         train_model_fn=train_model,\n",
    "                         wrap_model_fn=wrap_model_multilabel,\n",
    "                         times=100,\n",
    "                         num_days=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = results_to_df_mapie_multilabel(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:09:50.022159Z",
     "iopub.status.busy": "2024-08-15T02:09:50.021839Z",
     "iopub.status.idle": "2024-08-15T02:12:34.915717Z",
     "shell.execute_reply": "2024-08-15T02:12:34.914581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'{prefix}results_df__multi-label__mapie_100x__per_run_timespans__no_leak__w_demographic_covariates.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Exclude Demographic Covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = \\\n",
    "    run_experiment_mapie(daily_df=daily_df,\n",
    "                         demographic_df=None,\n",
    "                         label_df=labels,\n",
    "                         get_model_fn=get_model_multilabel, \n",
    "                         train_model_fn=train_model,\n",
    "                         wrap_model_fn=wrap_model_multilabel,\n",
    "                         times=100,\n",
    "                         num_days=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = results_to_df_mapie_multilabel(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### Save Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:09:50.022159Z",
     "iopub.status.busy": "2024-08-15T02:09:50.021839Z",
     "iopub.status.idle": "2024-08-15T02:12:34.915717Z",
     "shell.execute_reply": "2024-08-15T02:12:34.914581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(f'{prefix}results_df__multi-label__mapie_100x__per_run_timespans__no_leak__wout_demographic_covariates.csv', index=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MAPIE - Base vs Conformal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Read in Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-15T02:09:50.022159Z",
     "iopub.status.busy": "2024-08-15T02:09:50.021839Z",
     "iopub.status.idle": "2024-08-15T02:12:34.915717Z",
     "shell.execute_reply": "2024-08-15T02:12:34.914581Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "prefix = f'{my_bucket}/data/dfs/'\n",
    "\n",
    "df_ml_wd = results_csv_to_df_mapie(f'{prefix}results_df__multi-label__mapie_100x__per_run_timespans__no_leak__w_demographic_covariates.csv')\n",
    "df_ml_wo = results_csv_to_df_mapie(f'{prefix}results_df__multi-label__mapie_100x__per_run_timespans__no_leak__wout_demographic_covariates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Multi-Label - MAPIE - Get % Recall/Precision Base vs CP per Run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Aggregate Multi-Label - Row per Person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# aggregate up to one row per person per run\n",
    "def aggregate_ml_to_single_row_per_example(df):\n",
    "    # Convert boolean columns to integers\n",
    "    df[['crc', 'rcps', 'ltt']] = df[['crc', 'rcps', 'ltt']].astype(int)\n",
    "    \n",
    "    # Group by 'run' and 'example_idx', then aggregate relevant columns\n",
    "    df_grouped = df.groupby(['run', 'example_idx']).agg({\n",
    "        'crc': list,\n",
    "        'rcps': list,\n",
    "        'ltt': list,\n",
    "        'y_true': list,\n",
    "        'y_pred_prob_base_clf': list,\n",
    "        'person_id': set\n",
    "    }).reset_index()\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    df_grouped['crc'] = df_grouped['crc'].apply(np.array)\n",
    "    df_grouped['rcps'] = df_grouped['rcps'].apply(np.array)\n",
    "    df_grouped['ltt'] = df_grouped['ltt'].apply(np.array)\n",
    "    df_grouped['y_true'] = df_grouped['y_true'].apply(np.array)\n",
    "    df_grouped['y_pred_prob_base_clf'] = df_grouped['y_pred_prob_base_clf'].apply(np.array)\n",
    "    df_grouped['person_id'] = df_grouped['person_id'].apply(lambda x: x.pop())\n",
    "    \n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Metrics Multi-Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [`base`,`crc`,`rcps`,`ltt`]\n",
    "  - [`recall`,`precision`]\n",
    "    - [`micro`,`macro`,`weighted`]\n",
    "  - `avg_prediction_set_size`\n",
    "  - `total_false_positives`\n",
    "  - `total_false_negatives`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def calculate_metrics_with_base(group):\n",
    "    metrics = {}\n",
    "    \n",
    "    # Convert prediction probabilities to binary predictions using a threshold of 0.5\n",
    "    base_predictions = (np.vstack(group['y_pred_prob_base_clf']) >= 0.5).astype(int)\n",
    "    \n",
    "    for method in ['crc', 'rcps', 'ltt', 'base']:\n",
    "        if method == 'base':\n",
    "            method_predictions = base_predictions\n",
    "        else:\n",
    "            method_predictions = np.vstack(group[method])\n",
    "        \n",
    "        y_true = np.vstack(group['y_true'])\n",
    "        \n",
    "        # Calculate precision and recall for micro, macro, and weighted averages\n",
    "        for avg in ['micro', 'macro', 'weighted']:\n",
    "            precision = precision_score(y_true, method_predictions, average=avg, zero_division=0)\n",
    "            recall = recall_score(y_true, method_predictions, average=avg)\n",
    "            metrics[f'{method}_precision_{avg}'] = precision\n",
    "            metrics[f'{method}_recall_{avg}'] = recall\n",
    "        \n",
    "        # Calculate the average prediction set size\n",
    "        avg_pred_set_size = method_predictions.sum(axis=1).mean()\n",
    "        metrics[f'{method}_avg_prediction_set_size'] = avg_pred_set_size\n",
    "        \n",
    "        # Calculate total false positives and total false negatives\n",
    "        false_positives = ((method_predictions == 1) & (y_true == 0)).sum()\n",
    "        false_negatives = ((method_predictions == 0) & (y_true == 1)).sum()\n",
    "        \n",
    "        metrics[f'{method}_total_false_positives'] = false_positives\n",
    "        metrics[f'{method}_total_false_negatives'] = false_negatives\n",
    "    \n",
    "    # Reorder the metrics\n",
    "    ordered_metrics = {}\n",
    "    for metric in ['recall', 'precision']:\n",
    "        for avg in ['micro', 'macro', 'weighted']:\n",
    "            for method in ['base', 'crc', 'rcps', 'ltt']:\n",
    "                ordered_metrics[f'{method}_{metric}_{avg}'] = metrics[f'{method}_{metric}_{avg}']\n",
    "    \n",
    "    for method in ['base', 'crc', 'rcps', 'ltt']:\n",
    "        ordered_metrics[f'{method}_avg_prediction_set_size'] = metrics[f'{method}_avg_prediction_set_size']\n",
    "        ordered_metrics[f'{method}_total_false_positives'] = metrics[f'{method}_total_false_positives']\n",
    "        ordered_metrics[f'{method}_total_false_negatives'] = metrics[f'{method}_total_false_negatives']\n",
    "        \n",
    "    return pd.Series(ordered_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Print Metrics (CSV format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_df_in_csv_format(df):\n",
    "    import sys\n",
    "\n",
    "    # Create a string from the column names with no spaces between them\n",
    "    header = ','.join(df.columns)\n",
    "\n",
    "    # Print the header\n",
    "    print(header)\n",
    "\n",
    "    # Print each row in thxe DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        # Create a string from each row with no spaces between the values\n",
    "        row_str = ','.join(map(str, row.values))\n",
    "        print(row_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, df in [('df_ml_wd', df_ml_wd), ('df_ml_wo', df_ml_wo)]:\n",
    "    is_with_demographics = False\n",
    "    if 'wd' in name:\n",
    "        is_with_demographics = True\n",
    "        \n",
    "    result = df.groupby('run').apply(calculate_metrics_with_base).reset_index()   \n",
    "    \n",
    "    for col in result.columns:\n",
    "        if 'total_false' in col:\n",
    "            result[col] = result[col].astype(int)\n",
    "    \n",
    "    result['with_demographics'] = is_with_demographics\n",
    "    results.append(result)\n",
    "\n",
    "print_df_in_csv_format(df_ml_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
