{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Check Workspace and Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "now = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "\n",
    "Create function to set seeds for reproducibility\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def set_seeds():\n",
    "    import os\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Set the seed for the Python random module\n",
    "    random.seed(42)\n",
    "\n",
    "    # Set the seed for TensorFlow\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    # Ensure reproducibility with certain environment variables\n",
    "    os.environ['PYTHONHASHSEED'] = '42'\n",
    "\n",
    "\n",
    "    ### Hold off on more extensive seeds (below) until verified necessary\n",
    "\n",
    "\n",
    "    # # Configure TensorFlow to use a single thread if required\n",
    "    # tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "    # tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "\n",
    "    # # Optionally, set environment variables to control NumPy threading behavior\n",
    "    # os.environ['OMP_NUM_THREADS'] = '1'\n",
    "    # os.environ['MKL_NUM_THREADS'] = '1'\n",
    "\n",
    "    # # Example to demonstrate reproducibility\n",
    "    # print(\"Numpy Random:\", np.random.rand(3))\n",
    "    # print(\"Python Random:\", random.random())\n",
    "\n",
    "    # # TensorFlow example\n",
    "    # tf_example = tf.random.uniform([3])\n",
    "    # print(\"TensorFlow Random:\", tf_example)\n",
    "\n",
    "    # # PyTorch Example (if using PyTorch)\n",
    "    # import torch\n",
    "\n",
    "    # torch.manual_seed(42)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.cuda.manual_seed(42)\n",
    "    #     torch.cuda.manual_seed_all(42)  # if using multi-GPU.\n",
    "    #     torch.backends.cudnn.deterministic = True  # cuDNN\n",
    "    #     torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    # # Generate reproducible random numbers with PyTorch\n",
    "    # print(\"PyTorch Random:\", torch.rand(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "\n",
    "Create function to start/stop logging RAM usage to file\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import threading\n",
    "import time\n",
    "from google.cloud import storage\n",
    "\n",
    "def log_memory_usage(stop_event, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        while not stop_event.is_set():\n",
    "            # Log memory usage to a local file\n",
    "            memory_info = psutil.virtual_memory()\n",
    "            gb_used = memory_info.used / (1024 ** 3)\n",
    "            mem_usage = f\"{time.ctime()}: {gb_used:.2f} GB\\n\"\n",
    "            print(mem_usage)\n",
    "            f.write(mem_usage)\n",
    "            f.flush()\n",
    "            \n",
    "            # Upload the local file to GCS\n",
    "            try:\n",
    "                destination_blob_name = f'logs/{file_name}'\n",
    "                upload_to_gcs(file_name, destination_blob_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to upload to GCS: {e}\")\n",
    "                \n",
    "            time.sleep(30)\n",
    "            \n",
    "def upload_to_gcs(source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # Get the bucket name\n",
    "    my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "    # Initialize a storage client\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(my_bucket[5:])\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Upload the file\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "#     print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_event = threading.Event()\n",
    "memory_thread = None\n",
    "thread_lock = threading.Lock()  # To ensure thread-safe operations\n",
    "\n",
    "def RAM_start():\n",
    "    global stop_event\n",
    "    global memory_thread\n",
    "\n",
    "    with thread_lock:\n",
    "        # Clear the stop event if it is set\n",
    "        if stop_event.is_set():\n",
    "            stop_event.clear()\n",
    "\n",
    "        file_name = 'memory_usage.txt'\n",
    "        \n",
    "        # Stop the existing thread if it is running\n",
    "        if memory_thread and memory_thread.is_alive():\n",
    "            RAM_stop()\n",
    "        \n",
    "        # Create and start a new memory logging thread\n",
    "        memory_thread = threading.Thread(target=log_memory_usage, args=(stop_event, file_name))\n",
    "        memory_thread.start()\n",
    "        print(\"Memory logging started\")\n",
    "\n",
    "def RAM_stop():\n",
    "    global stop_event\n",
    "    global memory_thread\n",
    "\n",
    "    with thread_lock:\n",
    "        # Set the stop event to signal the thread to stop\n",
    "        stop_event.set()\n",
    "\n",
    "        # Wait for the thread to finish if it exists\n",
    "        if memory_thread:\n",
    "            memory_thread.join()\n",
    "            memory_thread = None  # Reset the thread to None\n",
    "            print(\"Memory logging stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RAM_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Anxiety Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     18
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSum+Anxiety\" for domain \"fitbit_activity\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_29237714_fitbit_activity_sql = \"\"\"\n",
    "    SELECT\n",
    "        activity_summary.person_id,\n",
    "        activity_summary.date,\n",
    "        activity_summary.activity_calories,\n",
    "        activity_summary.calories_bmr,\n",
    "        activity_summary.calories_out,\n",
    "        activity_summary.elevation,\n",
    "        activity_summary.fairly_active_minutes,\n",
    "        activity_summary.floors,\n",
    "        activity_summary.lightly_active_minutes,\n",
    "        activity_summary.marginal_calories,\n",
    "        activity_summary.sedentary_minutes,\n",
    "        activity_summary.steps,\n",
    "        activity_summary.very_active_minutes \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".activity_summary` activity_summary   \n",
    "    WHERE\n",
    "        activity_summary.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (442077)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_29237714_fitbit_activity_df = pandas.read_gbq(\n",
    "    dataset_29237714_fitbit_activity_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Heart Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # This query represents dataset \"AllFitbitSum+Anxiety\" for domain \"fitbit_heart_rate_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "# dataset_29237714_fitbit_heart_rate_summary_sql = \"\"\"\n",
    "#     SELECT\n",
    "#         heart_rate_summary.person_id,\n",
    "#         heart_rate_summary.date,\n",
    "#         heart_rate_summary.zone_name,\n",
    "#         heart_rate_summary.min_heart_rate,\n",
    "#         heart_rate_summary.max_heart_rate,\n",
    "#         heart_rate_summary.minute_in_zone,\n",
    "#         heart_rate_summary.calorie_count \n",
    "#     FROM\n",
    "#         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_summary` heart_rate_summary   \n",
    "#     WHERE\n",
    "#         heart_rate_summary.PERSON_ID IN (SELECT\n",
    "#             distinct person_id  \n",
    "#         FROM\n",
    "#             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "#         WHERE\n",
    "#             cb_search_person.person_id IN (SELECT\n",
    "#                 person_id \n",
    "#             FROM\n",
    "#                 `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "#             WHERE\n",
    "#                 has_fitbit = 1 ) \n",
    "#             AND cb_search_person.person_id IN (SELECT\n",
    "#                 criteria.person_id \n",
    "#             FROM\n",
    "#                 (SELECT\n",
    "#                     DISTINCT person_id, entry_date, concept_id \n",
    "#                 FROM\n",
    "#                     `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "#                 WHERE\n",
    "#                     (concept_id IN(SELECT\n",
    "#                         DISTINCT c.concept_id \n",
    "#                     FROM\n",
    "#                         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "#                     JOIN\n",
    "#                         (SELECT\n",
    "#                             CAST(cr.id as string) AS id       \n",
    "#                         FROM\n",
    "#                             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "#                         WHERE\n",
    "#                             concept_id IN (442077)       \n",
    "#                             AND full_text LIKE '%_rank1]%'      ) a \n",
    "#                             ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "#                             OR c.path LIKE CONCAT('%.', a.id) \n",
    "#                             OR c.path LIKE CONCAT(a.id, '.%') \n",
    "#                             OR c.path = a.id) \n",
    "#                     WHERE\n",
    "#                         is_standard = 1 \n",
    "#                         AND is_selectable = 1) \n",
    "#                     AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "# dataset_29237714_fitbit_heart_rate_summary_df = pandas.read_gbq(\n",
    "#     dataset_29237714_fitbit_heart_rate_summary_sql,\n",
    "#     dialect=\"standard\",\n",
    "#     use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "#     progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     17
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSum+Anxiety\" for domain \"fitbit_sleep_daily_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_29237714_fitbit_sleep_daily_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        sleep_daily_summary.person_id,\n",
    "        sleep_daily_summary.sleep_date,\n",
    "        sleep_daily_summary.is_main_sleep,\n",
    "        sleep_daily_summary.minute_in_bed,\n",
    "        sleep_daily_summary.minute_asleep,\n",
    "        sleep_daily_summary.minute_after_wakeup,\n",
    "        sleep_daily_summary.minute_awake,\n",
    "        sleep_daily_summary.minute_restless,\n",
    "        sleep_daily_summary.minute_deep,\n",
    "        sleep_daily_summary.minute_light,\n",
    "        sleep_daily_summary.minute_rem,\n",
    "        sleep_daily_summary.minute_wake \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".sleep_daily_summary` sleep_daily_summary   \n",
    "    WHERE\n",
    "        PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (442077)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_29237714_fitbit_sleep_daily_summary_df = pandas.read_gbq(\n",
    "    dataset_29237714_fitbit_sleep_daily_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     18
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSummaries+Depression\" for domain \"fitbit_activity\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_78185922_fitbit_activity_sql = \"\"\"\n",
    "    SELECT\n",
    "        activity_summary.person_id,\n",
    "        activity_summary.date,\n",
    "        activity_summary.activity_calories,\n",
    "        activity_summary.calories_bmr,\n",
    "        activity_summary.calories_out,\n",
    "        activity_summary.elevation,\n",
    "        activity_summary.fairly_active_minutes,\n",
    "        activity_summary.floors,\n",
    "        activity_summary.lightly_active_minutes,\n",
    "        activity_summary.marginal_calories,\n",
    "        activity_summary.sedentary_minutes,\n",
    "        activity_summary.steps,\n",
    "        activity_summary.very_active_minutes \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".activity_summary` activity_summary   \n",
    "    WHERE\n",
    "        activity_summary.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (440383)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_78185922_fitbit_activity_df = pandas.read_gbq(\n",
    "    dataset_78185922_fitbit_activity_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Heart rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # This query represents dataset \"AllFitbitSummaries+Depression\" for domain \"fitbit_heart_rate_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "# dataset_78185922_fitbit_heart_rate_summary_sql = \"\"\"\n",
    "#     SELECT\n",
    "#         heart_rate_summary.person_id,\n",
    "#         heart_rate_summary.date,\n",
    "#         heart_rate_summary.zone_name,\n",
    "#         heart_rate_summary.min_heart_rate,\n",
    "#         heart_rate_summary.max_heart_rate,\n",
    "#         heart_rate_summary.minute_in_zone,\n",
    "#         heart_rate_summary.calorie_count \n",
    "#     FROM\n",
    "#         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_summary` heart_rate_summary   \n",
    "#     WHERE\n",
    "#         heart_rate_summary.PERSON_ID IN (SELECT\n",
    "#             distinct person_id  \n",
    "#         FROM\n",
    "#             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "#         WHERE\n",
    "#             cb_search_person.person_id IN (SELECT\n",
    "#                 person_id \n",
    "#             FROM\n",
    "#                 `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "#             WHERE\n",
    "#                 has_fitbit = 1 ) \n",
    "#             AND cb_search_person.person_id IN (SELECT\n",
    "#                 criteria.person_id \n",
    "#             FROM\n",
    "#                 (SELECT\n",
    "#                     DISTINCT person_id, entry_date, concept_id \n",
    "#                 FROM\n",
    "#                     `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "#                 WHERE\n",
    "#                     (concept_id IN(SELECT\n",
    "#                         DISTINCT c.concept_id \n",
    "#                     FROM\n",
    "#                         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "#                     JOIN\n",
    "#                         (SELECT\n",
    "#                             CAST(cr.id as string) AS id       \n",
    "#                         FROM\n",
    "#                             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "#                         WHERE\n",
    "#                             concept_id IN (440383)       \n",
    "#                             AND full_text LIKE '%_rank1]%'      ) a \n",
    "#                             ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "#                             OR c.path LIKE CONCAT('%.', a.id) \n",
    "#                             OR c.path LIKE CONCAT(a.id, '.%') \n",
    "#                             OR c.path = a.id) \n",
    "#                     WHERE\n",
    "#                         is_standard = 1 \n",
    "#                         AND is_selectable = 1) \n",
    "#                     AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "# dataset_78185922_fitbit_heart_rate_summary_df = pandas.read_gbq(\n",
    "#     dataset_78185922_fitbit_heart_rate_summary_sql,\n",
    "#     dialect=\"standard\",\n",
    "#     use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "#     progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     17
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSummaries+Depression\" for domain \"fitbit_sleep_daily_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_78185922_fitbit_sleep_daily_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        sleep_daily_summary.person_id,\n",
    "        sleep_daily_summary.sleep_date,\n",
    "        sleep_daily_summary.is_main_sleep,\n",
    "        sleep_daily_summary.minute_in_bed,\n",
    "        sleep_daily_summary.minute_asleep,\n",
    "        sleep_daily_summary.minute_after_wakeup,\n",
    "        sleep_daily_summary.minute_awake,\n",
    "        sleep_daily_summary.minute_restless,\n",
    "        sleep_daily_summary.minute_deep,\n",
    "        sleep_daily_summary.minute_light,\n",
    "        sleep_daily_summary.minute_rem,\n",
    "        sleep_daily_summary.minute_wake \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".sleep_daily_summary` sleep_daily_summary   \n",
    "    WHERE\n",
    "        PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (440383)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_78185922_fitbit_sleep_daily_summary_df = pandas.read_gbq(\n",
    "    dataset_78185922_fitbit_sleep_daily_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## No Disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Physical Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     18
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSum-AnxDep\" for domain \"fitbit_activity\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_22083694_fitbit_activity_sql = \"\"\"\n",
    "    SELECT\n",
    "        activity_summary.person_id,\n",
    "        activity_summary.date,\n",
    "        activity_summary.activity_calories,\n",
    "        activity_summary.calories_bmr,\n",
    "        activity_summary.calories_out,\n",
    "        activity_summary.elevation,\n",
    "        activity_summary.fairly_active_minutes,\n",
    "        activity_summary.floors,\n",
    "        activity_summary.lightly_active_minutes,\n",
    "        activity_summary.marginal_calories,\n",
    "        activity_summary.sedentary_minutes,\n",
    "        activity_summary.steps,\n",
    "        activity_summary.very_active_minutes \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".activity_summary` activity_summary   \n",
    "    WHERE\n",
    "        activity_summary.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (440383, 442077)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_22083694_fitbit_activity_df = pandas.read_gbq(\n",
    "    dataset_22083694_fitbit_activity_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Heart Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     12
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # This query represents dataset \"AllFitbitSum-AnxDep\" for domain \"fitbit_heart_rate_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "# dataset_22083694_fitbit_heart_rate_summary_sql = \"\"\"\n",
    "#     SELECT\n",
    "#         heart_rate_summary.person_id,\n",
    "#         heart_rate_summary.date,\n",
    "#         heart_rate_summary.zone_name,\n",
    "#         heart_rate_summary.min_heart_rate,\n",
    "#         heart_rate_summary.max_heart_rate,\n",
    "#         heart_rate_summary.minute_in_zone,\n",
    "#         heart_rate_summary.calorie_count \n",
    "#     FROM\n",
    "#         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_summary` heart_rate_summary   \n",
    "#     WHERE\n",
    "#         heart_rate_summary.PERSON_ID IN (SELECT\n",
    "#             distinct person_id  \n",
    "#         FROM\n",
    "#             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "#         WHERE\n",
    "#             cb_search_person.person_id IN (SELECT\n",
    "#                 person_id \n",
    "#             FROM\n",
    "#                 `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "#             WHERE\n",
    "#                 has_fitbit = 1 ) \n",
    "#             AND cb_search_person.person_id NOT IN (SELECT\n",
    "#                 criteria.person_id \n",
    "#             FROM\n",
    "#                 (SELECT\n",
    "#                     DISTINCT person_id, entry_date, concept_id \n",
    "#                 FROM\n",
    "#                     `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "#                 WHERE\n",
    "#                     (concept_id IN(SELECT\n",
    "#                         DISTINCT c.concept_id \n",
    "#                     FROM\n",
    "#                         `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "#                     JOIN\n",
    "#                         (SELECT\n",
    "#                             CAST(cr.id as string) AS id       \n",
    "#                         FROM\n",
    "#                             `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "#                         WHERE\n",
    "#                             concept_id IN (440383, 442077)       \n",
    "#                             AND full_text LIKE '%_rank1]%'      ) a \n",
    "#                             ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "#                             OR c.path LIKE CONCAT('%.', a.id) \n",
    "#                             OR c.path LIKE CONCAT(a.id, '.%') \n",
    "#                             OR c.path = a.id) \n",
    "#                     WHERE\n",
    "#                         is_standard = 1 \n",
    "#                         AND is_selectable = 1) \n",
    "#                     AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "# dataset_22083694_fitbit_heart_rate_summary_df = pandas.read_gbq(\n",
    "#     dataset_22083694_fitbit_heart_rate_summary_sql,\n",
    "#     dialect=\"standard\",\n",
    "#     use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "#     progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "# dataset_22083694_fitbit_heart_rate_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     17
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This query represents dataset \"AllFitbitSum-AnxDep\" for domain \"fitbit_sleep_daily_summary\" and was generated for All of Us Registered Tier Dataset v7\n",
    "dataset_22083694_fitbit_sleep_daily_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        sleep_daily_summary.person_id,\n",
    "        sleep_daily_summary.sleep_date,\n",
    "        sleep_daily_summary.is_main_sleep,\n",
    "        sleep_daily_summary.minute_in_bed,\n",
    "        sleep_daily_summary.minute_asleep,\n",
    "        sleep_daily_summary.minute_after_wakeup,\n",
    "        sleep_daily_summary.minute_awake,\n",
    "        sleep_daily_summary.minute_restless,\n",
    "        sleep_daily_summary.minute_deep,\n",
    "        sleep_daily_summary.minute_light,\n",
    "        sleep_daily_summary.minute_rem,\n",
    "        sleep_daily_summary.minute_wake \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".sleep_daily_summary` sleep_daily_summary   \n",
    "    WHERE\n",
    "        PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                person_id \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p \n",
    "            WHERE\n",
    "                has_fitbit = 1 ) \n",
    "            AND cb_search_person.person_id NOT IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (440383, 442077)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_22083694_fitbit_sleep_daily_summary_df = pandas.read_gbq(\n",
    "    dataset_22083694_fitbit_sleep_daily_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_22083694_fitbit_sleep_daily_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Demographics & Heart Rate Level "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "  \n",
    "---  \n",
    "\n",
    "__For each Cohort:__\n",
    "\n",
    "- Anxiety\n",
    "- Depression\n",
    "- No Anxiety AND No Depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define queries for different cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These queries represent datasets\n",
    "\n",
    "- \"Fitbit_SleepActSum_HRlevel+Depression\"\n",
    "- \"Fitbit_SleepActSum_HRlevel+Anxiety\"\n",
    "- \"Fitbit_SleepActSum_HRlevel-AnxDep\"\n",
    "\n",
    "for domain \n",
    "\n",
    "- \"fitbit_heart_rate_level\" \n",
    "- \"person\"\n",
    "\n",
    "and was generated for All of Us Registered Tier Dataset v7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define queries for different cohorts\n",
    "cohorts = {\n",
    "    'depression': 440383,\n",
    "    'anxiety': 442077,\n",
    "    'not_anxiety_depression': [440383, 442077]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Base SQL template - HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Base SQL template - HR\n",
    "sql_template_hr = \"\"\"\n",
    "    SELECT\n",
    "        heart_rate_minute_level.person_id,\n",
    "        CAST(heart_rate_minute_level.datetime AS DATE) as date,\n",
    "        AVG(heart_rate_value) as mean_hr,\n",
    "        APPROX_QUANTILES(heart_rate_value, 2)[OFFSET(1)] as median_hr,\n",
    "        STDDEV(heart_rate_value) as std_hr,\n",
    "        MIN(heart_rate_value) as min_hr,\n",
    "        MAX(heart_rate_value) as max_hr,\n",
    "        MAX(heart_rate_value) - MIN(heart_rate_value) as range_hr,\n",
    "        COUNT(heart_rate_value) as count_hr,\n",
    "        SUM(CASE WHEN heart_rate_value < 60 THEN 1 ELSE 0 END) / COUNT(heart_rate_value) as proportion_resting,\n",
    "        SUM(CASE WHEN heart_rate_value BETWEEN 60 AND 100 THEN 1 ELSE 0 END) / COUNT(heart_rate_value) as proportion_moderate,\n",
    "        SUM(CASE WHEN heart_rate_value > 100 THEN 1 ELSE 0 END) / COUNT(heart_rate_value) as proportion_high,\n",
    "        AVG(CASE WHEN EXTRACT(HOUR FROM datetime) BETWEEN 6 AND 11 THEN heart_rate_value ELSE NULL END) as morning_hr,\n",
    "        AVG(CASE WHEN EXTRACT(HOUR FROM datetime) BETWEEN 12 AND 17 THEN heart_rate_value ELSE NULL END) as afternoon_hr,\n",
    "        AVG(CASE WHEN EXTRACT(HOUR FROM datetime) BETWEEN 18 AND 23 THEN heart_rate_value ELSE NULL END) as evening_hr,\n",
    "        AVG(CASE WHEN EXTRACT(HOUR FROM datetime) BETWEEN 0 AND 5 THEN heart_rate_value ELSE NULL END) as night_hr\n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_minute_level` heart_rate_minute_level\n",
    "    WHERE\n",
    "        heart_rate_minute_level.PERSON_ID IN (SELECT \n",
    "                DISTINCT person_id\n",
    "            FROM \n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person\n",
    "            WHERE \n",
    "                cb_search_person.person_id IN (SELECT \n",
    "                    person_id\n",
    "                FROM \n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p\n",
    "                WHERE \n",
    "                    has_fitbit = 1 )\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Base SQL template - Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Base SQL template - Demographics\n",
    "sql_template_demographics = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "                distinct person_id\n",
    "            FROM \n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person\n",
    "            WHERE \n",
    "                cb_search_person.person_id IN (SELECT \n",
    "                    person_id\n",
    "                FROM \n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` p\n",
    "                WHERE \n",
    "                    has_fitbit = 1 )\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Add conditions for specific cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add conditions for specific cohorts\n",
    "def get_sql_for_cohort_demographics(cohort, concept_ids):\n",
    "    in_or_not = \"\"\"\n",
    "                AND cb_search_person.person_id IN (\"\"\"\n",
    "    if cohort.startswith('not_'):\n",
    "        in_or_not = \"\"\"\n",
    "                AND cb_search_person.person_id NOT IN (\"\"\"\n",
    "\n",
    "    if isinstance(concept_ids, list):\n",
    "        concept_condition = \", \".join([f\"{cid}\" for cid in concept_ids])\n",
    "    else:\n",
    "        concept_condition = f\"{concept_ids}\"\n",
    "        \n",
    "    return sql_template_demographics + in_or_not + f\"\"\"SELECT \n",
    "                    criteria.person_id\n",
    "                FROM\n",
    "                    (SELECT\n",
    "                        DISTINCT person_id, entry_date, concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                    WHERE\n",
    "                        (concept_id IN(SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (SELECT\n",
    "                                CAST(cr.id as string) AS id       \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + f\"\"\".cb_criteria` cr       \n",
    "                            WHERE\n",
    "                                concept_id IN ({concept_condition})       \n",
    "                                AND full_text LIKE '%_rank1]%'      ) a \n",
    "                                ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                                OR c.path LIKE CONCAT('%.', a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                                OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1) \n",
    "                        AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add conditions for specific cohorts\n",
    "def get_sql_for_cohort_hr(cohort, concept_ids):\n",
    "    in_or_not = \"\"\"\n",
    "                AND cb_search_person.person_id IN (\"\"\"\n",
    "    if cohort.startswith('not_'):\n",
    "        in_or_not = \"\"\"\n",
    "                AND cb_search_person.person_id NOT IN (\"\"\"\n",
    "\n",
    "    if isinstance(concept_ids, list):\n",
    "        concept_condition = \", \".join([f\"{cid}\" for cid in concept_ids])\n",
    "    else:\n",
    "        concept_condition = f\"{concept_ids}\"\n",
    "        \n",
    "    return sql_template_hr + in_or_not + f\"\"\"SELECT \n",
    "                    criteria.person_id\n",
    "                FROM\n",
    "                    (SELECT\n",
    "                        DISTINCT person_id, entry_date, concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                    WHERE\n",
    "                        (concept_id IN(SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (SELECT\n",
    "                                CAST(cr.id as string) AS id       \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + f\"\"\".cb_criteria` cr       \n",
    "                            WHERE\n",
    "                                concept_id IN ({concept_condition})       \n",
    "                                AND full_text LIKE '%_rank1]%'      ) a \n",
    "                                ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                                OR c.path LIKE CONCAT('%.', a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                                OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1) \n",
    "                        AND is_standard = 1 )) criteria ) )\n",
    "    GROUP BY\n",
    "        person_id,\n",
    "        date\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Generate SQL for each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate SQL for each cohort\n",
    "queries_hr = \\\n",
    "    {cohort: get_sql_for_cohort_hr(cohort, concept_ids) for cohort, concept_ids in cohorts.items()}\n",
    "\n",
    "queries_demographics = \\\n",
    "    {cohort: get_sql_for_cohort_demographics(cohort, concept_ids) for cohort, concept_ids in cohorts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Review SQL for each cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for q in queries_hr.keys():\n",
    "    print()\n",
    "    print(q)\n",
    "    print()\n",
    "    print('HR:')\n",
    "    print(queries_hr[q])\n",
    "    print()\n",
    "    print('demographics:')\n",
    "    print(queries_demographics[q])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Retrieve Data from GBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to retrieve data from GBQ\n",
    "def load_data_from_gbq(sql_query):\n",
    "    return pd.read_gbq(\n",
    "        sql_query,\n",
    "        dialect=\"standard\",\n",
    "        use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "        progress_bar_type=\"tqdm_notebook\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load data for each cohort\n",
    "data_hr = {cohort: load_data_from_gbq(sql) for cohort, sql in queries_hr.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load data for each cohort\n",
    "data_demo = {cohort: load_data_from_gbq(sql) for cohort, sql in queries_demographics.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_anx_hr = data_hr['anxiety']\n",
    "df_anx_demo = data_demo['anxiety']\n",
    "df_dep_hr = data_hr['depression']\n",
    "df_dep_demo = data_demo['depression']\n",
    "df_no_anx_dep_hr = data_hr['not_anxiety_depression']\n",
    "df_no_anx_dep_demo = data_demo['not_anxiety_depression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_anx_demo.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(df_anx_hr.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_anx_hr.shape)\n",
    "print(df_anx_demo.shape)\n",
    "print(df_dep_hr.shape)\n",
    "print(df_dep_demo.shape)\n",
    "print(df_no_anx_dep_hr.shape)\n",
    "print(df_no_anx_dep_demo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Write DFs to file to save ~45min in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write Demographic and HR data to CSVs\n",
    "\n",
    "dfs_names = [\n",
    "    ('df_anx_hr', df_anx_hr),\n",
    "    ('df_anx_demo', df_anx_demo),\n",
    "    ('df_dep_hr', df_dep_hr),\n",
    "    ('df_dep_demo', df_dep_demo),\n",
    "    ('df_no_anx_dep_hr', df_no_anx_dep_hr),\n",
    "    ('df_no_anx_dep_demo', df_no_anx_dep_demo)\n",
    "]\n",
    "\n",
    "for df_name, df in dfs_names:\n",
    "    df.to_csv(f\"{my_bucket}/data/dfs/{df_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Above adds new HR data aggregated from `minute_level`  \n",
    "\n",
    "___per `daily_summary` in v7 of the dataset is broken (only 1 zone/person/day)___\n",
    "\n",
    "(so removed below)\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs_names = ['dataset_22083694_fitbit_activity_df',\n",
    "#              'dataset_22083694_fitbit_heart_rate_summary_df',\n",
    "             'dataset_22083694_fitbit_sleep_daily_summary_df',\n",
    "             'dataset_29237714_fitbit_activity_df',\n",
    "#              'dataset_29237714_fitbit_heart_rate_summary_df',\n",
    "             'dataset_29237714_fitbit_sleep_daily_summary_df',\n",
    "             'dataset_78185922_fitbit_activity_df',\n",
    "#              'dataset_78185922_fitbit_heart_rate_summary_df',\n",
    "             'dataset_78185922_fitbit_sleep_daily_summary_df'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfs = [dataset_22083694_fitbit_activity_df,\n",
    "#        dataset_22083694_fitbit_heart_rate_summary_df,\n",
    "       dataset_22083694_fitbit_sleep_daily_summary_df,\n",
    "       dataset_29237714_fitbit_activity_df,\n",
    "#        dataset_29237714_fitbit_heart_rate_summary_df,\n",
    "       dataset_29237714_fitbit_sleep_daily_summary_df,\n",
    "       dataset_78185922_fitbit_activity_df,\n",
    "#        dataset_78185922_fitbit_heart_rate_summary_df,\n",
    "       dataset_78185922_fitbit_sleep_daily_summary_df\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df, df_name in zip(dfs, dfs_names):\n",
    "    df.to_csv(f\"{my_bucket}/data/dfs/{df_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Read DFs from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "RAM_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_anx_hr = pd.read_csv(f\"{my_bucket}/data/dfs/df_anx_hr.csv\", index_col=0)\n",
    "df_anx_demo = pd.read_csv(f\"{my_bucket}/data/dfs/df_anx_demo.csv\", index_col=0)\n",
    "df_dep_hr = pd.read_csv(f\"{my_bucket}/data/dfs/df_dep_hr.csv\", index_col=0)\n",
    "df_dep_demo = pd.read_csv(f\"{my_bucket}/data/dfs/df_dep_demo.csv\", index_col=0)\n",
    "df_no_anx_dep_hr = pd.read_csv(f\"{my_bucket}/data/dfs/df_no_anx_dep_hr.csv\", index_col=0)\n",
    "df_no_anx_dep_demo = pd.read_csv(f\"{my_bucket}/data/dfs/df_no_anx_dep_demo.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_22083694_fitbit_activity_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_22083694_fitbit_activity_df.csv\", index_col=0)\n",
    "# dataset_22083694_fitbit_heart_rate_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_22083694_fitbit_heart_rate_summary_df.csv\", index_col=0)\n",
    "dataset_22083694_fitbit_sleep_daily_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_22083694_fitbit_sleep_daily_summary_df.csv\", index_col=0)\n",
    "dataset_29237714_fitbit_activity_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_29237714_fitbit_activity_df.csv\", index_col=0)\n",
    "# dataset_29237714_fitbit_heart_rate_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_29237714_fitbit_heart_rate_summary_df.csv\", index_col=0)\n",
    "dataset_29237714_fitbit_sleep_daily_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_29237714_fitbit_sleep_daily_summary_df.csv\", index_col=0)\n",
    "dataset_78185922_fitbit_activity_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_78185922_fitbit_activity_df.csv\", index_col=0)\n",
    "# dataset_78185922_fitbit_heart_rate_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_78185922_fitbit_heart_rate_summary_df.csv\", index_col=0)\n",
    "dataset_78185922_fitbit_sleep_daily_summary_df = pd.read_csv(f\"{my_bucket}/data/dfs/dataset_78185922_fitbit_sleep_daily_summary_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#physical activity data\n",
    "dep_act_df = dataset_78185922_fitbit_activity_df\n",
    "anx_act_df = dataset_29237714_fitbit_activity_df\n",
    "absent_act_df = dataset_22083694_fitbit_activity_df\n",
    "\n",
    "#heart rate data\n",
    "# dep_heart_df = dataset_78185922_fitbit_heart_rate_summary_df\n",
    "# anx_heart_df = dataset_29237714_fitbit_heart_rate_summary_df\n",
    "# absent_heart_df = dataset_22083694_fitbit_heart_rate_summary_df\n",
    "\n",
    "#heart rate data\n",
    "dep_heart_df = df_dep_hr\n",
    "anx_heart_df = df_anx_hr\n",
    "absent_heart_df = df_no_anx_dep_hr\n",
    "\n",
    "#demographic data\n",
    "dep_demo_df = df_dep_demo\n",
    "anx_demo_df = df_anx_demo\n",
    "absent_demo_df = df_no_anx_dep_demo\n",
    "\n",
    "#sleep data\n",
    "dep_sleep_df = dataset_78185922_fitbit_sleep_daily_summary_df\n",
    "anx_sleep_df = dataset_29237714_fitbit_sleep_daily_summary_df\n",
    "absent_sleep_df = dataset_22083694_fitbit_sleep_daily_summary_df\n",
    "\n",
    "# anx_idx = np.unique(list(anx_sleep_df['person_id']) + list(anx_act_df['person_id']) + list(anx_heart_df['person_id']))\n",
    "# anx_labels = pd.Series(1,index=anx_idx)\n",
    "# dep_idx = np.unique(list(dep_sleep_df['person_id']) + list(dep_act_df['person_id']) + list(dep_heart_df['person_id']))\n",
    "# dep_labels = pd.Series(1,index=dep_idx)\n",
    "# absent_idx = np.unique(list(absent_sleep_df['person_id']) + list(absent_act_df['person_id']) + list(absent_heart_df['person_id']))\n",
    "# absent_labels = pd.Series(1,index=absent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(f\"intersect:\\n{pd.Index(anx_sleep_df['person_id']).intersection(anx_act_df['person_id']).intersection(anx_demo_df['person_id']).intersection(anx_heart_df['person_id']).unique()}\")\n",
    "print()\n",
    "print('vs')\n",
    "print()\n",
    "print(f\"union:\\n{pd.Index(anx_sleep_df['person_id']).union(anx_act_df['person_id']).union(anx_demo_df['person_id']).union(anx_heart_df['person_id']).unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__PER ABOVE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Choosing `intersection` per ensures individuals have data for all (sleep, activity, heart, demographic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract unique person_ids and create labels\n",
    "anx_idx = pd.Index(anx_sleep_df['person_id']).intersection(\n",
    "                     anx_act_df['person_id']).intersection(\n",
    "                     anx_demo_df['person_id']).intersection(\n",
    "                     anx_heart_df['person_id']).unique()\n",
    "anx_labels = pd.Series(1, index=anx_idx)\n",
    "\n",
    "dep_idx = pd.Index(dep_sleep_df['person_id']).intersection(\n",
    "                     dep_act_df['person_id']).intersection(\n",
    "                     dep_demo_df['person_id']).intersection(\n",
    "                     dep_heart_df['person_id']).unique()\n",
    "dep_labels = pd.Series(1, index=dep_idx)\n",
    "\n",
    "absent_idx = pd.Index(absent_sleep_df['person_id']).intersection(\n",
    "                        absent_act_df['person_id']).intersection(\n",
    "                        absent_demo_df['person_id']).intersection(\n",
    "                        absent_heart_df['person_id']).unique()\n",
    "absent_labels = pd.Series(1, index=absent_idx)\n",
    "\n",
    "\n",
    "# # Extract unique person_ids and create labels\n",
    "# anx_idx = pd.Index(anx_sleep_df['person_id']).union(anx_act_df['person_id']).union(anx_heart_df['person_id']).unique()\n",
    "# anx_labels = pd.Series(1, index=anx_idx)\n",
    "\n",
    "# dep_idx = pd.Index(dep_sleep_df['person_id']).union(dep_act_df['person_id']).union(dep_heart_df['person_id']).unique()\n",
    "# dep_labels = pd.Series(1, index=dep_idx)\n",
    "\n",
    "# absent_idx = pd.Index(absent_sleep_df['person_id']).union(absent_act_df['person_id']).union(absent_heart_df['person_id']).unique()\n",
    "# absent_labels = pd.Series(1, index=absent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = pd.concat([anx_labels,dep_labels,absent_labels],axis=1,join='outer')\n",
    "labels = labels.fillna(0).astype(int).rename(columns={0:'Anxiety disorder',1:'Depressive disorder',2:'No disorder'})\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "act_df = pd.concat([dep_act_df,anx_act_df,absent_act_df])\n",
    "act_df = act_df.drop_duplicates(subset=['person_id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "heart_df = pd.concat([dep_heart_df,anx_heart_df,absent_heart_df])\n",
    "heart_df = heart_df.drop_duplicates(subset=['person_id', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "demo_df = pd.concat([dep_demo_df,anx_demo_df,absent_demo_df])\n",
    "demo_df = demo_df.drop_duplicates(subset=['person_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "demo_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ensure the date_of_birth field is in datetime format\n",
    "demo_df['date_of_birth'] = pd.to_datetime(demo_df['date_of_birth'])\n",
    "\n",
    "# Function to calculate age\n",
    "def calculate_age(born):\n",
    "    today = datetime.now()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "\n",
    "# Apply the function to calculate age for each person\n",
    "demo_df['age'] = demo_df['date_of_birth'].apply(calculate_age)\n",
    "demo_df = demo_df.drop(columns=['date_of_birth'])\n",
    "demo_df = demo_df.drop(columns=['gender_concept_id','race_concept_id','ethnicity_concept_id','sex_at_birth_concept_id'])\n",
    "demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(demo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "demo_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Demographic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in ['gender','race','ethnicity','sex_at_birth','age']:\n",
    "    print()\n",
    "    print(demo_df[i].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Later ('Scale and Split') exclusion of 'naps' would not work properly (per subset=[`person_id`,`sleep_date`] without considering `is_main_sleep`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sleep_df = pd.concat([dep_sleep_df,anx_sleep_df,absent_sleep_df])\n",
    "# sleep_df = sleep_df.drop_duplicates(subset=['person_id', 'sleep_date'])\n",
    "sleep_df = sleep_df.drop_duplicates(subset=['person_id', 'sleep_date', 'is_main_sleep'])\n",
    "\n",
    "# test_person_id = sleep_df['person_id'].unique()[5]\n",
    "\n",
    "# test_person_sleep_df = sleep_df[sleep_df['person_id']==test_person_id]\n",
    "# test_person_main_sleep_df = test_person_sleep_df[test_person_sleep_df['is_main_sleep']=='true']\n",
    "\n",
    "# test_person_sleep_df.plot('sleep_date','minute_asleep',figsize=[20,5])\n",
    "# test_person_main_sleep_df.plot('sleep_date','minute_asleep',figsize=[20,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sleep - `is_main_sleep` naps example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp = pd.concat([dep_sleep_df,anx_sleep_df,absent_sleep_df])\n",
    "\n",
    "# Group by 'person_id' and 'date', then count the occurrences\n",
    "grouped = temp.groupby(['person_id', 'sleep_date']).size().reset_index(name='count')\n",
    "\n",
    "# Filter groups that have more than one row\n",
    "mult_per_date = grouped[grouped['count'] > 1]\n",
    "print(mult_per_date.head(3).tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mult_dates = mult_per_date['sleep_date'].unique()\n",
    "\n",
    "# Filter the temp DataFrame for the specified person_id and sleep_date in mult_dates\n",
    "filtered_temp = temp[(temp['person_id'] == 1000107) & (temp['sleep_date'].isin(mult_dates))]\n",
    "\n",
    "filtered_temp.sort_values('sleep_date').head(15).tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "variables_to_delete = ['temp', 'grouped', 'mult_per_date']\n",
    "\n",
    "for var in variables_to_delete:\n",
    "    try:\n",
    "        # Attempt to delete each variable\n",
    "        del globals()[var]\n",
    "    except KeyError:\n",
    "        # Handle the case where the variable does not exist\n",
    "        print(f\"Variable '{var}' does not exist and cannot be deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### HR Zone (currently N/A per source data flawed in v7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# RAM_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Takes a while, write to CSV below and read from instead of re-running (unless change something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# zone_names = ['Cardio', 'Out of Range', 'Fat Burn', 'Peak']\n",
    "# zone_dfs = []\n",
    "\n",
    "# # Iterate over each unique person_id\n",
    "# for id in heart_df['person_id'].unique():\n",
    "#     person_df = heart_df[heart_df['person_id'] == id]\n",
    "    \n",
    "#     # Initialize a DataFrame to store the person's data\n",
    "#     person_zone_df = pd.DataFrame({'date': person_df['date'].unique()})\n",
    "#     person_zone_df['person_id'] = id\n",
    "    \n",
    "#     # For each zone, pivot the minute_in_zone data\n",
    "#     for zone in zone_names:\n",
    "#         temp_df = person_df[person_df['zone_name'] == zone][['date', 'minute_in_zone']]\n",
    "#         temp_df = temp_df.rename(columns={'minute_in_zone': zone})\n",
    "#         person_zone_df = pd.merge(person_zone_df, temp_df, on='date', how='left')\n",
    "    \n",
    "#     # Append the person's DataFrame to the list\n",
    "#     zone_dfs.append(person_zone_df)\n",
    "\n",
    "# # Concatenate all individual person DataFrames\n",
    "# zone_df = pd.concat(zone_dfs, ignore_index=True)\n",
    "\n",
    "# # Fill NaN values with 0 (or appropriate value based on context)\n",
    "# zone_df = zone_df.fillna(0)\n",
    "\n",
    "# zone_df\n",
    "\n",
    "\n",
    "# # Above uses ~10 GB below uses > 100 GB\n",
    "# #\n",
    "# # #Munge heart rate dataset so each zone is own column\n",
    "# # zone_names = ['Cardio', 'Out of Range', 'Fat Burn', 'Peak']\n",
    "# # dfs = []\n",
    "\n",
    "# # for id in heart_df['person_id'].unique():\n",
    "# #     person_df = heart_df[heart_df['person_id']==id]\n",
    "# #     for zone in zone_names:\n",
    "# #         temp_df = person_df[person_df['zone_name']==zone]\n",
    "# #         temp_df = temp_df[['person_id','date','minute_in_zone']].rename(columns={'minute_in_zone':zone})\n",
    "# #         dfs.append(temp_df)\n",
    "\n",
    "# # zone_df = pd.concat(dfs,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Write CSV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# zone_df.to_csv(f\"{my_bucket}/data/dfs/zone_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# zone_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Read CSV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# zone_df = pd.read_csv(f\"{my_bucket}/data/dfs/zone_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# zone_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "----\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Nobody has more than 1 non-zero value for a given date (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Define the columns to check\n",
    "# columns_to_check = ['Cardio', 'Out of Range', 'Fat Burn', 'Peak']\n",
    "\n",
    "# # Create a boolean DataFrame where each entry is True if the corresponding entry in the original DataFrame is non-zero\n",
    "# non_zero = zone_df[columns_to_check] != 0\n",
    "\n",
    "# # Sum across the columns for each row to count non-zero entries\n",
    "# non_zero_counts = non_zero.sum(axis=1)\n",
    "\n",
    "# # Check if any row has more than one non-zero entry\n",
    "# rows_with_multiple_non_zero = zone_df[non_zero_counts > 1]\n",
    "\n",
    "# # Display the rows with more than one non-zero value\n",
    "# print(rows_with_multiple_non_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# RAM_stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Merge df's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "NOTE:  \n",
    "  \n",
    "Below merge will duplicate *_df rows for individuals who took a nap on a given date (`is_main_sleep` false, then true in another row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Merge all dataframes into one\n",
    "sleep_df = sleep_df.rename(columns={'sleep_date':'date'})\n",
    "\n",
    "# daily_df = sleep_df.merge(act_df,on=['person_id','date'],how='inner').merge(heart_df,on=['person_id','date'],how='inner')\n",
    "daily_df = sleep_df \\\n",
    "            .merge(act_df,on=['person_id','date'],how='inner') \\\n",
    "            .merge(heart_df,on=['person_id','date'],how='inner') ##\\\n",
    "            #.merge(demo_df,on=['person_id'],how='inner')        ## lots of duplication if done here\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### __summarize `daily_df`__ (first 5,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import plotnine\n",
    "from plotnine import *  # Provides a ggplot-like interface to matplotlib.\n",
    "from IPython.display import display\n",
    "\n",
    "## Plot setup.\n",
    "theme_set(theme_bw(base_size = 11)) # Default theme for plots.\n",
    "\n",
    "def get_boxplot_fun_data(df):\n",
    "  \"\"\"Returns a data frame with a y position and a label, for use annotating ggplot boxplots.\n",
    "\n",
    "  Args:\n",
    "    d: A data frame.\n",
    "  Returns:\n",
    "    A data frame with column y as max and column label as length.\n",
    "  \"\"\"\n",
    "  d = {'y': max(df), 'label': f'N = {len(df)}'}\n",
    "  return(pd.DataFrame(data=d, index=[0]))\n",
    "\n",
    "# NOTE: if you get any errors from this cell, restart your kernel and run it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Use snippet 'summarize_a_dataframe' to display summary statistics for a dataframe.\n",
    "# # It assumes snippet 'Setup' has been executed.\n",
    "# # See also https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82d\n",
    "\n",
    "\n",
    "# ## -----[ CHANGE THE DATAFRAME NAME(S) TO MATCH YOURS FROM DATASET BUILDER] -----\n",
    "# daily_df.loc[:5000,:].profile_report()  # Examine up to the first 10,000 rows. Larger\n",
    "#                                         # dataframes can be profiled, but it takes more time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Use snippet 'summarize_a_dataframe' to display summary statistics for a dataframe.\n",
    "# # It assumes snippet 'Setup' has been executed.\n",
    "# # See also https://towardsdatascience.com/exploring-your-data-with-just-1-line-of-python-4b35ce21a82d\n",
    "\n",
    "\n",
    "# ## -----[ CHANGE THE DATAFRAME NAME(S) TO MATCH YOURS FROM DATASET BUILDER] -----\n",
    "# demo_df.loc[:,:].profile_report()         # Examine up to the first 10,000 rows. Larger\n",
    "#                                         # dataframes can be profiled, but it takes more time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Are there any people with more than one row per date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('Total number of patients: '+str(len(np.unique(daily_df.person_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Group by 'person_id' and 'date', then count the occurrences\n",
    "grouped = daily_df.groupby(['person_id', 'date']).size().reset_index(name='count')\n",
    "\n",
    "# Filter groups that have more than one row\n",
    "print(grouped[grouped['count'] > 1])\n",
    "\n",
    "del grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "___Yes, but only 2 rows per date per naps (`is_main_sleep` True & False)___\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Write `daily_df` to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "\n",
    "(`daily_df_v2.csv`, `daily_df_labels_v2.csv`, `demographics_df.csv`)\n",
    "\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# daily_df.to_csv(f\"{my_bucket}/data/dfs/daily_df.csv\", index=False)\n",
    "# labels.to_csv(f\"{my_bucket}/data/dfs/daily_df_labels.csv\")\n",
    "\n",
    "# added HR data from `minute_level` source\n",
    "daily_df.to_csv(f\"daily_df_v2.csv\", index=False)\n",
    "labels.to_csv(f\"daily_df_labels_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write corresponding Demographics to CSV\n",
    "demo_df.to_csv(f\"demographics_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!gsutil cp daily_df_v2.csv {my_bucket}/data/dfs/daily_df_v2.csv\n",
    "!gsutil cp daily_df_labels_v2.csv {my_bucket}/data/dfs/daily_df_labels_v2.csv\n",
    "!gsutil cp demographics_df.csv {my_bucket}/data/dfs/demographics_df.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls {my_bucket}/data/dfs\", shell=True).decode('utf-8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
